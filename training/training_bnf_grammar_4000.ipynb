{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded epoch_154\n"
     ]
    }
   ],
   "source": [
    "# Init/Load model\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "# Define a directory to save the models\n",
    "SAVE_DIR = '../saved_models'\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "start_epoch = 160\n",
    "\n",
    "class SimpleBART(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleBART, self).__init__()\n",
    "        if start_epoch > 0:\n",
    "            self.bart = BartForConditionalGeneration.from_pretrained(os.path.join(SAVE_DIR, f'epoch_{start_epoch}'))\n",
    "            print(f'Loaded epoch_{start_epoch}')\n",
    "        else:\n",
    "            self.bart = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "            print('Loaded facebook/bart-base')\n",
    "        self.tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.bart(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "\n",
    "model = SimpleBART().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Raw Datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import csv\n",
    "\n",
    "ACCUMULATION_STEPS = 14\n",
    "BATCH_SIZE = 14 # best performing batch size so far (in execution performance)\n",
    "DATA_SIZE = 0\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=200):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        self.start_token_id = tokenizer.cls_token_id\n",
    "        self.end_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text, tokens = self.data[idx]\n",
    "        \n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=self.max_length)\n",
    "        \n",
    "        # Add start and end tokens and then pad\n",
    "        tokens = [self.start_token_id] + tokens + [self.end_token_id]\n",
    "        tokens_padded = [self.pad_token_id] * self.max_length\n",
    "        tokens_padded[:len(tokens)] = tokens\n",
    "        tokens_padded[len(tokens):] = [self.pad_token_id] * (self.max_length - len(tokens))\n",
    "        \n",
    "        return inputs[\"input_ids\"].squeeze(0), inputs[\"attention_mask\"].squeeze(0), torch.tensor(tokens_padded, dtype=torch.long)\n",
    "\n",
    "\n",
    "def load_data_from_csv(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        data = [(row[0], [int(tok) for tok in row[1].split(\",\")]) for row in reader]\n",
    "\n",
    "    return data\n",
    "\n",
    "def apply_concept(params, validation=False):\n",
    "    global validationLoader\n",
    "    global dataloader\n",
    "    global DATA_SIZE\n",
    "\n",
    "    merged_data = load_data_from_csv(f\"../concept/egg.csv\")\n",
    "    \n",
    "    print(\"Concepts loaded;\")\n",
    "    for file_name, percentage in params.items():\n",
    "        data = load_data_from_csv(f\"../concept/{file_name}.csv\")\n",
    "        cutoff = int(len(data) * percentage)\n",
    "        \n",
    "        if validation:\n",
    "            loaded_data = data[-cutoff:]\n",
    "        else:\n",
    "            loaded_data = data[:cutoff]\n",
    "\n",
    "        print(f\"    - {file_name}: {len(loaded_data)}\")\n",
    "        merged_data.extend(loaded_data)\n",
    "\n",
    "    DATA_SIZE = len(merged_data)\n",
    "    dataset = CustomDataset(merged_data, model.tokenizer)\n",
    "    if validation:\n",
    "        validationLoader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    else:\n",
    "        dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    print(f'  Total: {DATA_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Validator\n",
    "def validate():\n",
    "    EOS_TOKEN_ID = model.tokenizer.eos_token_id\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize counters for accuracy calculation\n",
    "    total_correct_sequences = 0\n",
    "    total_sequences = 0\n",
    "\n",
    "    # Initialize counters for average sequence accuracy within the mask\n",
    "    total_accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input_ids, attention_mask, targets) in enumerate(validationLoader):\n",
    "            input_ids, attention_mask, targets = input_ids.to(device), attention_mask.to(device), targets.to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Identify where the EOS token is in the target sequence\n",
    "            eos_positions = (targets == EOS_TOKEN_ID).cumsum(dim=1).type(torch.bool)\n",
    "            mask = ~eos_positions | (targets == EOS_TOKEN_ID)\n",
    "\n",
    "            _, predicted = logits.max(2)\n",
    "            correct_sequences = ((predicted == targets) | ~mask).all(dim=1).float().sum().item()\n",
    "            total_sequences += targets.size(0)\n",
    "            total_correct_sequences += correct_sequences\n",
    "\n",
    "            # Compute the accuracy for each sequence\n",
    "            correct_tokens_per_sequence = ((predicted == targets) & mask).float().sum(dim=1)\n",
    "            total_tokens_per_sequence = mask.float().sum(dim=1)\n",
    "            total_accuracy += (correct_tokens_per_sequence / total_tokens_per_sequence).sum().item()\n",
    "\n",
    "    # Compute and print the accuracy for the entire validation dataset\n",
    "    validation_accuracy = total_correct_sequences / total_sequences\n",
    "    print(f\"  Total Seq Acc: {validation_accuracy*100:.3f}%\")\n",
    "    avg_accuracy = total_accuracy / total_sequences\n",
    "    print(f\"    Avg Seq Acc: {avg_accuracy*100:.3f}%\")\n",
    "\n",
    "    return avg_accuracy, validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup trainer\n",
    "def save_model():\n",
    "    global start_epoch\n",
    "    model_save_path = os.path.join(SAVE_DIR, f'epoch_{start_epoch}')\n",
    "    model.bart.save_pretrained(model_save_path)\n",
    "\n",
    "def trainFor(num_epochs, target_loss=0, target_p50_loss=0, target_acc=1.0, target_seq_acc=1.0):\n",
    "    global start_epoch\n",
    "\n",
    "    EOS_TOKEN_ID = model.tokenizer.eos_token_id\n",
    "    acc_batch = int(ACCUMULATION_STEPS / BATCH_SIZE)\n",
    "    total_batches = len(dataloader)\n",
    "\n",
    "    for epoch in range(start_epoch+1, start_epoch+num_epochs+1):\n",
    "        start_epoch = epoch\n",
    "        model.train()\n",
    "\n",
    "        # Resetting the accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Initialize counters for accuracy calculation\n",
    "        total_correct_sequences = 0\n",
    "        total_sequences = 0\n",
    "        cumulative_loss = 0.0\n",
    "\n",
    "        # Initialize list to store batch losses\n",
    "        batch_losses = []\n",
    "\n",
    "        for batch_idx, (input_ids, attention_mask, targets) in enumerate(dataloader):\n",
    "\n",
    "            input_ids, attention_mask, targets = input_ids.to(device), attention_mask.to(device), targets.to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Identify where the EOS token is in the target sequence\n",
    "            eos_positions = (targets == EOS_TOKEN_ID).cumsum(dim=1).type(torch.bool)\n",
    "            mask = ~eos_positions | (targets == EOS_TOKEN_ID)\n",
    "\n",
    "            # Apply mask to filter out tokens after the EOS token for loss computation\n",
    "            active_loss = mask.view(-1).bool()\n",
    "            active_logits = logits.view(-1, logits.size(-1))[active_loss]\n",
    "            active_labels = targets.view(-1)[active_loss]\n",
    "            loss = criterion(active_logits, active_labels)\n",
    "\n",
    "            _, predicted = logits.max(2)\n",
    "            correct_sequences = ((predicted == targets) | ~mask).all(dim=1).float().sum().item()\n",
    "            total_sequences += targets.size(0)\n",
    "            total_correct_sequences += correct_sequences\n",
    "\n",
    "            # Accumulate the gradients\n",
    "            loss.backward()\n",
    "            loss_val = loss.item()\n",
    "\n",
    "            cumulative_loss += loss_val\n",
    "            batch_losses.append(loss_val)\n",
    "\n",
    "            isLast = batch_idx == len(dataloader) - 1\n",
    "\n",
    "            # Only perform an optimization step every ACCUMULATION_STEPS\n",
    "            if isLast or batch_idx % acc_batch == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            print(f\"\\rEpoch: {epoch}, Batch: {batch_idx} of {total_batches}, loss: {loss_val:.6f}      \", end='')\n",
    "\n",
    "\n",
    "        # Compute and print the accuracy for the entire epoch\n",
    "        epoch_accuracy = total_correct_sequences / total_sequences\n",
    "        cumulative_loss = cumulative_loss / len(batch_losses)\n",
    "        p25_loss = np.percentile(batch_losses, 25)\n",
    "        p50_loss = np.percentile(batch_losses, 50)\n",
    "        p75_loss = np.percentile(batch_losses, 75)\n",
    "        print(f\"\\rEpoch: {epoch}, Accuracy: {epoch_accuracy*100:.2f}%                                             \")\n",
    "        print(f\"  Loss: 25%: {p25_loss:.6f} 50%: {p50_loss:.6f} 75%: {p75_loss:.6f}\\n   Avg: {cumulative_loss:.6f}\")\n",
    "\n",
    "        if epoch % 10 == 0: # Save the model\n",
    "            save_model()\n",
    "\n",
    "        seq_acc, total_acc = validate()\n",
    "\n",
    "        if total_acc >= target_acc:\n",
    "            break\n",
    "        if cumulative_loss <= target_loss:\n",
    "            break\n",
    "        if p50_loss <= target_p50_loss:\n",
    "            break\n",
    "\n",
    "        if seq_acc >= target_seq_acc:\n",
    "            break\n",
    "\n",
    "    # Make sure last epoch is always saved\n",
    "    save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 3122\n",
      "  Total: 9931\n",
      "Epoch: 1, Accuracy: 0.01%\n",
      "  Loss: 25%: 4.393126 50%: 4.887876 75%: 5.315798\n",
      "   Avg: 4.884056\n",
      "  Total Seq Acc: 0.000%\n",
      "    Avg Seq Acc: 39.868%\n",
      "Epoch: 2, Accuracy: 0.03%\n",
      "  Loss: 25%: 4.117525 50%: 4.550774 75%: 4.877478\n",
      "   Avg: 4.482987\n",
      "  Total Seq Acc: 0.004%\n",
      "    Avg Seq Acc: 39.875%\n",
      "Epoch: 3, Accuracy: 0.03%\n",
      "  Loss: 25%: 4.068293 50%: 4.452379 75%: 4.818588\n",
      "   Avg: 4.398917\n",
      "  Total Seq Acc: 0.062%\n",
      "    Avg Seq Acc: 39.897%\n",
      "Epoch: 4, Accuracy: 0.05%\n",
      "  Loss: 25%: 4.008659 50%: 4.428133 75%: 4.759971\n",
      "   Avg: 4.360003\n",
      "  Total Seq Acc: 0.085%\n",
      "    Avg Seq Acc: 39.924%\n",
      "Epoch: 5, Accuracy: 0.16%\n",
      "  Loss: 25%: 3.946199 50%: 4.349040 75%: 4.712277\n",
      "   Avg: 4.299947\n",
      "  Total Seq Acc: 0.214%\n",
      "    Avg Seq Acc: 40.006%\n",
      "Epoch: 6, Accuracy: 0.48%\n",
      "  Loss: 25%: 3.817751 50%: 4.224310 75%: 4.577750\n",
      "   Avg: 4.175182\n",
      "  Total Seq Acc: 1.057%\n",
      "    Avg Seq Acc: 40.588%\n",
      "Epoch: 7, Accuracy: 2.34%\n",
      "  Loss: 25%: 3.542352 50%: 3.961223 75%: 4.297835\n",
      "   Avg: 3.902212\n",
      "  Total Seq Acc: 3.791%\n",
      "    Avg Seq Acc: 43.450%\n",
      "Epoch: 8, Accuracy: 6.20%\n",
      "  Loss: 25%: 3.052983 50%: 3.451971 75%: 3.804974\n",
      "   Avg: 3.416453\n",
      "  Total Seq Acc: 8.795%\n",
      "    Avg Seq Acc: 50.804%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = BATCH_SIZE # pure memorisation so accumulation won't help\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.02})\n",
    "trainFor(50, target_seq_acc=0.50)\n",
    "# (31mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 6245\n",
      "  Total: 13054\n",
      "Epoch: 9, Accuracy: 10.68%\n",
      "  Loss: 25%: 2.948524 50%: 3.301470 75%: 3.602107\n",
      "   Avg: 3.285144\n",
      "  Total Seq Acc: 16.104%\n",
      "    Avg Seq Acc: 63.344%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = BATCH_SIZE # pure memorisation so accumulation won't help\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.04})\n",
    "trainFor(50, target_seq_acc=0.60)\n",
    "# (4mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 9368\n",
      "  Total: 16177\n",
      "Epoch: 10, Accuracy: 14.79%\n",
      "  Loss: 25%: 2.290249 50%: 2.601158 75%: 2.916466\n",
      "   Avg: 2.600121\n",
      "  Total Seq Acc: 25.349%\n",
      "    Avg Seq Acc: 75.091%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 28 # *14 close to 32\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.06})\n",
    "trainFor(50, target_seq_acc=0.65)\n",
    "# (5mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aiming for:\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\frac{unique}{tokens} &= \\frac{4174}{6808} = 61.31\\%  & \\text{sign pairs to text only used once} \\\\\n",
    "  \\frac{text}{tokens}   &= \\frac{5342}{6808}  = 78.47\\% & \\text{sign pairs to text unique text} \\\\\n",
    "  & & \\text{unique meaning the text is only used for one tokenID}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "i.e. there are six different signs which can be used for \"present\"  \n",
    "which means we're actually aiming for $96\\%$ effective accuracy $\\frac{75\\%}{78\\%}$\n",
    "\n",
    "But we don't want to over-fit either  \n",
    "Hence why we slowly introduce new concepts while still memorising vocabulary\n",
    "\n",
    "`target_seq_acc` includes the `EOS` token, which we of course we want to be right\n",
    "So our target should be $\\frac{61.31\\% + 100\\%}{2} = 80.65\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 12491\n",
      "  Total: 19300\n",
      "Epoch: 11, Accuracy: 18.79%\n",
      "  Loss: 25%: 1.740285 50%: 1.988600 75%: 2.250141\n",
      "   Avg: 2.004923\n",
      "  Total Seq Acc: 31.401%\n",
      "    Avg Seq Acc: 79.550%\n",
      "Epoch: 12, Accuracy: 23.83%\n",
      "  Loss: 25%: 1.321281 50%: 1.537223 75%: 1.742366\n",
      "   Avg: 1.547170\n",
      "  Total Seq Acc: 35.058%\n",
      "    Avg Seq Acc: 81.933%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 70 # *14 close to 64\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.08})\n",
    "trainFor(50, target_seq_acc=0.80655)\n",
    "# (10mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "  Total Seq Acc: 35.058%\n",
      "    Avg Seq Acc: 81.933%\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "  Total: 6809\n",
      "  Total Seq Acc: 62.109%\n",
      "    Avg Seq Acc: 87.325%\n",
      "Concepts loaded;\n",
      "    - noise: 15614\n",
      "  Total: 15615\n",
      "  Total Seq Acc: 23.260%\n",
      "    Avg Seq Acc: 79.579%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.795788674411047, 0.23259686199167467)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pure memorisation is over, as the vocabulary has been sufficiently learnt  \n",
    "While it's not perfect, it will improve further over the later training, as the vocab remains in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 35132\n",
      "  Total: 41941\n",
      "Epoch: 13, Accuracy: 19.62%\n",
      "  Loss: 25%: 1.276297 50%: 1.521877 75%: 1.806241\n",
      "   Avg: 1.567434\n",
      "  Total Seq Acc: 37.671%\n",
      "    Avg Seq Acc: 83.350%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 1022 # *14 close to 1024\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.225})\n",
    "trainFor(50, target_seq_acc=0.6)\n",
    "# (10mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "  Total: 6809\n",
      "  Total Seq Acc: 64.576%\n",
      "    Avg Seq Acc: 88.098%\n",
      "Concepts loaded;\n",
      "    - noise: 15614\n",
      "  Total: 15615\n",
      "  Total Seq Acc: 25.937%\n",
      "    Avg Seq Acc: 81.276%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8127563179130933, 0.25936599423631124)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Break down of validation per concept\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 70264\n",
      "  Total: 77073\n",
      "Epoch: 14, Accuracy: 21.77%\n",
      "  Loss: 25%: 0.978782 50%: 1.179458 75%: 1.420422\n",
      "   Avg: 1.226024\n",
      "  Total Seq Acc: 42.332%\n",
      "    Avg Seq Acc: 86.016%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 1022 # *14 close to 1024\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.45})\n",
    "trainFor(50, target_seq_acc=0.7)\n",
    "# (16mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "  Total Seq Acc: 42.332%\n",
      "    Avg Seq Acc: 86.016%\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "  Total: 6809\n",
      "  Total Seq Acc: 67.190%\n",
      "    Avg Seq Acc: 88.945%\n",
      "Concepts loaded;\n",
      "    - noise: 15614\n",
      "  Total: 15615\n",
      "  Total Seq Acc: 31.489%\n",
      "    Avg Seq Acc: 84.735%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8473481228669942, 0.3148895292987512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the model saved correctly\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 140528\n",
      "  Total: 147337\n",
      "Epoch: 15, Accuracy: 25.32%\n",
      "  Loss: 25%: 0.735360 50%: 0.893032 75%: 1.094783\n",
      "   Avg: 0.942284\n",
      "  Total Seq Acc: 46.069%\n",
      "    Avg Seq Acc: 87.619%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 1022 # *14 close to 1024\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.9})\n",
    "trainFor(50, target_seq_acc=0.75)\n",
    "# (29mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "  Total Seq Acc: 46.069%\n",
      "    Avg Seq Acc: 87.619%\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "  Total: 6809\n",
      "  Total Seq Acc: 69.863%\n",
      "    Avg Seq Acc: 89.861%\n",
      "Concepts loaded;\n",
      "    - noise: 15614\n",
      "  Total: 15615\n",
      "  Total Seq Acc: 35.690%\n",
      "    Avg Seq Acc: 86.637%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8663697381680721, 0.3569004162664105)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 140528\n",
      "  Total: 147337\n",
      "Epoch: 16, Accuracy: 29.25%\n",
      "  Loss: 25%: 0.571872 50%: 0.698485 75%: 0.865685\n",
      "   Avg: 0.749544\n",
      "  Total Seq Acc: 36.574%\n",
      "    Avg Seq Acc: 87.146%\n",
      "Epoch: 17, Accuracy: 31.80%\n",
      "  Loss: 25%: 0.486688 50%: 0.593760 75%: 0.741733\n",
      "   Avg: 0.647466\n",
      "  Total Seq Acc: 38.834%\n",
      "    Avg Seq Acc: 87.917%\n",
      "Epoch: 18, Accuracy: 33.24%\n",
      "  Loss: 25%: 0.436313 50%: 0.527889 75%: 0.659536\n",
      "   Avg: 0.579617\n",
      "  Total Seq Acc: 39.065%\n",
      "    Avg Seq Acc: 88.180%\n",
      "Epoch: 19, Accuracy: 34.66%\n",
      "  Loss: 25%: 0.394753 50%: 0.478254 75%: 0.594729\n",
      "   Avg: 0.527243\n",
      "  Total Seq Acc: 39.577%\n",
      "    Avg Seq Acc: 88.354%\n",
      "Epoch: 20, Accuracy: 35.63%\n",
      "  Loss: 25%: 0.367282 50%: 0.446331 75%: 0.552213\n",
      "   Avg: 0.491565\n",
      "  Total Seq Acc: 39.801%\n",
      "    Avg Seq Acc: 88.395%\n",
      "Epoch: 21, Accuracy: 36.52%\n",
      "  Loss: 25%: 0.344380 50%: 0.417024 75%: 0.515350\n",
      "   Avg: 0.460924\n",
      "  Total Seq Acc: 39.923%\n",
      "    Avg Seq Acc: 88.536%\n",
      "Epoch: 22, Accuracy: 37.15%\n",
      "  Loss: 25%: 0.327414 50%: 0.395074 75%: 0.487842\n",
      "   Avg: 0.439581\n",
      "  Total Seq Acc: 40.359%\n",
      "    Avg Seq Acc: 88.574%\n",
      "Epoch: 23, Accuracy: 37.71%\n",
      "  Loss: 25%: 0.313323 50%: 0.379837 75%: 0.466719\n",
      "   Avg: 0.421587\n",
      "  Total Seq Acc: 40.602%\n",
      "    Avg Seq Acc: 88.734%\n",
      "Epoch: 24, Accuracy: 38.17%\n",
      "  Loss: 25%: 0.303001 50%: 0.364846 75%: 0.447742\n",
      "   Avg: 0.403929\n",
      "  Total Seq Acc: 40.647%\n",
      "    Avg Seq Acc: 88.777%\n",
      "Epoch: 25, Accuracy: 38.67%\n",
      "  Loss: 25%: 0.290715 50%: 0.351060 75%: 0.427329\n",
      "   Avg: 0.386927\n",
      "  Total Seq Acc: 40.608%\n",
      "    Avg Seq Acc: 88.742%\n",
      "Epoch: 26, Accuracy: 38.95%\n",
      "  Loss: 25%: 0.282604 50%: 0.339503 75%: 0.412173\n",
      "   Avg: 0.375377\n",
      "  Total Seq Acc: 40.890%\n",
      "    Avg Seq Acc: 88.844%\n",
      "Epoch: 27, Accuracy: 39.26%\n",
      "  Loss: 25%: 0.276607 50%: 0.331959 75%: 0.404896\n",
      "   Avg: 0.368596\n",
      "  Total Seq Acc: 40.788%\n",
      "    Avg Seq Acc: 88.860%\n",
      "Epoch: 28, Accuracy: 39.62%\n",
      "  Loss: 25%: 0.269253 50%: 0.322100 75%: 0.391046\n",
      "   Avg: 0.357316\n",
      "  Total Seq Acc: 41.114%\n",
      "    Avg Seq Acc: 88.998%\n",
      "Epoch: 29, Accuracy: 39.94%\n",
      "  Loss: 25%: 0.262997 50%: 0.317211 75%: 0.381432\n",
      "   Avg: 0.349266\n",
      "  Total Seq Acc: 41.223%\n",
      "    Avg Seq Acc: 89.001%\n",
      "Epoch: 30, Accuracy: 40.06%\n",
      "  Loss: 25%: 0.258675 50%: 0.309745 75%: 0.373555\n",
      "   Avg: 0.341003\n",
      "  Total Seq Acc: 41.326%\n",
      "    Avg Seq Acc: 88.976%\n",
      "Epoch: 31, Accuracy: 40.41%\n",
      "  Loss: 25%: 0.251329 50%: 0.302622 75%: 0.366014\n",
      "   Avg: 0.333494\n",
      "  Total Seq Acc: 41.505%\n",
      "    Avg Seq Acc: 89.060%\n",
      "Epoch: 32, Accuracy: 40.68%\n",
      "  Loss: 25%: 0.247923 50%: 0.298805 75%: 0.361045\n",
      "   Avg: 0.330150\n",
      "  Total Seq Acc: 41.076%\n",
      "    Avg Seq Acc: 88.967%\n",
      "Epoch: 33, Accuracy: 40.69%\n",
      "  Loss: 25%: 0.247097 50%: 0.295387 75%: 0.355061\n",
      "   Avg: 0.324294\n",
      "  Total Seq Acc: 41.089%\n",
      "    Avg Seq Acc: 88.985%\n",
      "Epoch: 34, Accuracy: 40.82%\n",
      "  Loss: 25%: 0.242226 50%: 0.290121 75%: 0.348251\n",
      "   Avg: 0.319312\n",
      "  Total Seq Acc: 41.415%\n",
      "    Avg Seq Acc: 89.027%\n",
      "Epoch: 35, Accuracy: 41.01%\n",
      "  Loss: 25%: 0.237273 50%: 0.284986 75%: 0.342848\n",
      "   Avg: 0.313189\n",
      "  Total Seq Acc: 41.102%\n",
      "    Avg Seq Acc: 89.015%\n",
      "> KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 1022 # *14 close to 1024\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.9})\n",
    "trainFor(50, target_acc=0.8)\n",
    "# (583mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I accidentally set the `target_acc` which is accuracy of total sequences, instead of `target_seq_acc` which is the average accuracy of sequences, so this training stage had to be manually stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "  Total Seq Acc: 52.339%\n",
      "    Avg Seq Acc: 90.122%\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "  Total: 6809\n",
      "  Total Seq Acc: 78.132%\n",
      "    Avg Seq Acc: 92.685%\n",
      "Concepts loaded;\n",
      "    - noise: 15614\n",
      "  Total: 15615\n",
      "  Total Seq Acc: 41.089%\n",
      "    Avg Seq Acc: 89.000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8899978608990418, 0.41088696765930194)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 140528\n",
      "  Total: 147337\n",
      "Epoch: 36, Accuracy: 41.15%10525, loss: 0.603985      \n",
      "  Loss: 25%: 0.235659 50%: 0.282068 75%: 0.340233\n",
      "   Avg: 0.309650\n",
      "  Total Seq Acc: 52.727%\n",
      "    Avg Seq Acc: 90.170%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 1022 # *14 close to 1024\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.9})\n",
    "trainFor(50, target_p50_loss=0.2, target_seq_acc=0.90)\n",
    "# (31mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "  Total Seq Acc: 52.727%\n",
      "    Avg Seq Acc: 90.170%\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "  Total: 6809\n",
      "  Total Seq Acc: 78.249%\n",
      "    Avg Seq Acc: 92.715%\n",
      "Concepts loaded;\n",
      "    - noise: 15614\n",
      "  Total: 15615\n",
      "  Total Seq Acc: 41.595%\n",
      "    Avg Seq Acc: 89.056%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8905585711635232, 0.4159462055715658)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - word-masking: 10000\n",
      "  Total: 16809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - word-masking: 45000\n",
      "  Total: 51809\n",
      "Epoch: 37, Accuracy: 10.22%                                             \n",
      "  Loss: 25%: 5.452652 50%: 5.740592 75%: 6.173782\n",
      "   Avg: 5.867780\n",
      "  Total Seq Acc: 32.179%\n",
      "    Avg Seq Acc: 57.678%\n",
      "Epoch: 38, Accuracy: 10.30%                                             \n",
      "  Loss: 25%: 4.742584 50%: 4.972636 75%: 5.184268\n",
      "   Avg: 4.951151\n",
      "  Total Seq Acc: 32.340%\n",
      "    Avg Seq Acc: 60.602%\n",
      "Epoch: 39, Accuracy: 10.39%                                             \n",
      "  Loss: 25%: 4.270635 50%: 4.504084 75%: 4.723184\n",
      "   Avg: 4.476866\n",
      "  Total Seq Acc: 32.435%\n",
      "    Avg Seq Acc: 62.755%\n",
      "Epoch: 40, Accuracy: 10.53%                                             \n",
      "  Loss: 25%: 3.873336 50%: 4.118207 75%: 4.329885\n",
      "   Avg: 4.091265\n",
      "  Total Seq Acc: 32.506%\n",
      "    Avg Seq Acc: 64.345%\n",
      "Epoch: 41, Accuracy: 10.53%                                             \n",
      "  Loss: 25%: 3.587439 50%: 3.815478 75%: 4.017605\n",
      "   Avg: 3.792648\n",
      "  Total Seq Acc: 32.619%\n",
      "    Avg Seq Acc: 66.275%\n",
      "Epoch: 42, Accuracy: 10.42%                                             \n",
      "  Loss: 25%: 3.344392 50%: 3.570922 75%: 3.789108\n",
      "   Avg: 3.555688\n",
      "  Total Seq Acc: 32.703%\n",
      "    Avg Seq Acc: 68.184%\n",
      "Epoch: 43, Accuracy: 10.51%                                             \n",
      "  Loss: 25%: 3.159942 50%: 3.387740 75%: 3.597715\n",
      "   Avg: 3.370355\n",
      "  Total Seq Acc: 32.703%\n",
      "    Avg Seq Acc: 69.490%\n",
      "Epoch: 44, Accuracy: 10.58%                                             \n",
      "  Loss: 25%: 3.002264 50%: 3.240052 75%: 3.449829\n",
      "   Avg: 3.216751\n",
      "  Total Seq Acc: 32.691%\n",
      "    Avg Seq Acc: 68.949%\n",
      "Epoch: 45, Accuracy: 10.58%                                             \n",
      "  Loss: 25%: 2.871531 50%: 3.099282 75%: 3.314220\n",
      "   Avg: 3.086005\n",
      "  Total Seq Acc: 32.756%\n",
      "    Avg Seq Acc: 71.108%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 4088 # *14 close to 4096\n",
    "apply_concept({\"vocabulary\": 1.0, \"word-masking\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"word-masking\": 0.45})\n",
    "trainFor(20, target_p50_loss=0.2, target_seq_acc=0.70)\n",
    "# (106mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - word-masking: 10000\n",
      "  Total: 16809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - word-masking: 90000\n",
      "  Total: 96809\n",
      "Epoch: 46, Accuracy: 6.21%                                             \n",
      "  Loss: 25%: 2.853651 50%: 3.078444 75%: 3.296024\n",
      "   Avg: 3.069364\n",
      "  Total Seq Acc: 32.804%\n",
      "    Avg Seq Acc: 71.986%\n",
      "Epoch: 47, Accuracy: 6.24%                                             \n",
      "  Loss: 25%: 2.680615 50%: 2.886154 75%: 3.098930\n",
      "   Avg: 2.881209\n",
      "  Total Seq Acc: 32.643%\n",
      "    Avg Seq Acc: 70.560%\n",
      "Epoch: 48, Accuracy: 6.24%                                             \n",
      "  Loss: 25%: 2.540300 50%: 2.741766 75%: 2.946689\n",
      "   Avg: 2.741542\n",
      "  Total Seq Acc: 32.715%\n",
      "    Avg Seq Acc: 72.377%\n",
      "Epoch: 49, Accuracy: 6.31%                                             \n",
      "  Loss: 25%: 2.414057 50%: 2.623077 75%: 2.826812\n",
      "   Avg: 2.617838\n",
      "  Total Seq Acc: 32.727%\n",
      "    Avg Seq Acc: 72.722%\n",
      "Epoch: 50, Accuracy: 6.30%                                             \n",
      "  Loss: 25%: 2.293734 50%: 2.502753 75%: 2.705111\n",
      "   Avg: 2.498403\n",
      "  Total Seq Acc: 32.637%\n",
      "    Avg Seq Acc: 73.681%\n",
      "Epoch: 51, Accuracy: 6.39%                                             \n",
      "  Loss: 25%: 2.196455 50%: 2.392603 75%: 2.589688\n",
      "   Avg: 2.389779\n",
      "  Total Seq Acc: 32.602%\n",
      "    Avg Seq Acc: 74.935%\n",
      "Epoch: 52, Accuracy: 6.34%                                             \n",
      "  Loss: 25%: 2.095016 50%: 2.296974 75%: 2.486233\n",
      "   Avg: 2.288941\n",
      "  Total Seq Acc: 32.590%\n",
      "    Avg Seq Acc: 75.416%\n",
      "> KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 4088 # *14 close to 4096\n",
    "apply_concept({\"vocabulary\": 1.0, \"word-masking\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"word-masking\": 0.9})\n",
    "trainFor(20, target_p50_loss=0.2, target_seq_acc=0.9)\n",
    "# (151mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopped early, because the new samples are so much longer than the noise, the correct use of the EOS token isn't skewing the `avg seq acc` as much, hence we want to stop closer to our $78.47\\%$ accuracy estimate from before\n",
    "\n",
    "Taking this estimated maximum possible accuracy into account we have currently obtained a $\\frac{75.416\\%}{78.47\\%} = 96.12\\%$ accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 10000\n",
      "  Total: 16809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 50000\n",
      "  Total: 56809\n",
      "Epoch: 53, Accuracy: 8.17%                                             \n",
      "  Loss: 25%: 5.661148 50%: 5.839899 75%: 6.294619\n",
      "   Avg: 6.079971\n",
      "  Total Seq Acc: 30.924%\n",
      "    Avg Seq Acc: 48.485%\n",
      "Epoch: 54, Accuracy: 7.87%                                             \n",
      "  Loss: 25%: 5.338311 50%: 5.470820 75%: 5.596282\n",
      "   Avg: 5.461576\n",
      "  Total Seq Acc: 30.829%\n",
      "    Avg Seq Acc: 48.938%\n",
      "Epoch: 55, Accuracy: 7.57%                                             \n",
      "  Loss: 25%: 5.084069 50%: 5.227675 75%: 5.357668\n",
      "   Avg: 5.222457\n",
      "  Total Seq Acc: 30.365%\n",
      "    Avg Seq Acc: 49.104%\n",
      "Epoch: 56, Accuracy: 6.74%                                             \n",
      "  Loss: 25%: 4.944715 50%: 5.099912 75%: 5.235361\n",
      "   Avg: 5.089562\n",
      "  Total Seq Acc: 29.103%\n",
      "    Avg Seq Acc: 48.949%\n",
      "Epoch: 57, Accuracy: 5.98%                                             \n",
      "  Loss: 25%: 4.849137 50%: 5.000599 75%: 5.142462\n",
      "   Avg: 4.995960\n",
      "  Total Seq Acc: 27.729%\n",
      "    Avg Seq Acc: 48.816%\n",
      "Epoch: 58, Accuracy: 5.65%                                             \n",
      "  Loss: 25%: 4.767331 50%: 4.919853 75%: 5.073140\n",
      "   Avg: 4.917460\n",
      "  Total Seq Acc: 27.575%\n",
      "    Avg Seq Acc: 49.278%\n",
      "Epoch: 59, Accuracy: 5.65%                                             \n",
      "  Loss: 25%: 4.688171 50%: 4.855140 75%: 5.009246\n",
      "   Avg: 4.848101\n",
      "  Total Seq Acc: 27.848%\n",
      "    Avg Seq Acc: 49.813%\n",
      "Epoch: 60, Accuracy: 6.09%                                             \n",
      "  Loss: 25%: 4.639099 50%: 4.796405 75%: 4.955624\n",
      "   Avg: 4.790254\n",
      "  Total Seq Acc: 28.086%\n",
      "    Avg Seq Acc: 50.221%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 4088 # *14 close to 4096\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.50})\n",
    "trainFor(20, target_p50_loss=0.2, target_seq_acc=0.50)\n",
    "# (100mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 10000\n",
      "  Total: 16809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 60000\n",
      "  Total: 66809\n",
      "Epoch: 61, Accuracy: 5.37%                                             \n",
      "  Loss: 25%: 4.585829 50%: 4.748495 75%: 4.904201\n",
      "   Avg: 4.740234\n",
      "  Total Seq Acc: 28.277%\n",
      "    Avg Seq Acc: 50.651%\n",
      "Epoch: 62, Accuracy: 5.57%                                             \n",
      "  Loss: 25%: 4.519236 50%: 4.690837 75%: 4.850698\n",
      "   Avg: 4.681852\n",
      "  Total Seq Acc: 28.419%\n",
      "    Avg Seq Acc: 50.969%\n",
      "Epoch: 63, Accuracy: 5.73%                                             \n",
      "  Loss: 25%: 4.465399 50%: 4.640532 75%: 4.804271\n",
      "   Avg: 4.631159\n",
      "  Total Seq Acc: 28.610%\n",
      "    Avg Seq Acc: 51.342%\n",
      "Epoch: 64, Accuracy: 5.83%                                             \n",
      "  Loss: 25%: 4.427047 50%: 4.595013 75%: 4.751634\n",
      "   Avg: 4.584568\n",
      "  Total Seq Acc: 28.741%\n",
      "    Avg Seq Acc: 51.402%\n",
      "Epoch: 65, Accuracy: 5.89%                                             \n",
      "  Loss: 25%: 4.367585 50%: 4.535657 75%: 4.701467\n",
      "   Avg: 4.528181\n",
      "  Total Seq Acc: 28.657%\n",
      "    Avg Seq Acc: 51.738%\n",
      "Epoch: 66, Accuracy: 5.96%                                             \n",
      "  Loss: 25%: 4.330495 50%: 4.493066 75%: 4.653724\n",
      "   Avg: 4.483697\n",
      "  Total Seq Acc: 28.622%\n",
      "    Avg Seq Acc: 52.011%\n",
      "Epoch: 67, Accuracy: 6.15%                                             \n",
      "  Loss: 25%: 4.272056 50%: 4.446783 75%: 4.607317\n",
      "   Avg: 4.437323\n",
      "  Total Seq Acc: 28.925%\n",
      "    Avg Seq Acc: 52.490%\n",
      "Epoch: 68, Accuracy: 6.33%                                             \n",
      "  Loss: 25%: 4.227241 50%: 4.405962 75%: 4.567340\n",
      "   Avg: 4.392125\n",
      "  Total Seq Acc: 29.199%\n",
      "    Avg Seq Acc: 52.879%\n",
      "Epoch: 69, Accuracy: 6.39%                                             \n",
      "  Loss: 25%: 4.189248 50%: 4.365692 75%: 4.532021\n",
      "   Avg: 4.353310\n",
      "  Total Seq Acc: 29.431%\n",
      "    Avg Seq Acc: 53.121%\n",
      "Epoch: 70, Accuracy: 6.46%                                             \n",
      "  Loss: 25%: 4.152972 50%: 4.323364 75%: 4.493740\n",
      "   Avg: 4.316185\n",
      "  Total Seq Acc: 29.377%\n",
      "    Avg Seq Acc: 53.570%\n",
      "Epoch: 71, Accuracy: 6.48%                                             \n",
      "  Loss: 25%: 4.115338 50%: 4.295126 75%: 4.466765\n",
      "   Avg: 4.284878\n",
      "  Total Seq Acc: 29.454%\n",
      "    Avg Seq Acc: 53.918%\n",
      "Epoch: 72, Accuracy: 6.53%                                             \n",
      "  Loss: 25%: 4.066516 50%: 4.250153 75%: 4.422416\n",
      "   Avg: 4.235283\n",
      "  Total Seq Acc: 29.556%\n",
      "    Avg Seq Acc: 54.062%\n",
      "Epoch: 73, Accuracy: 6.54%                                             \n",
      "  Loss: 25%: 4.028638 50%: 4.210538 75%: 4.383951\n",
      "   Avg: 4.198610\n",
      "  Total Seq Acc: 29.603%\n",
      "    Avg Seq Acc: 54.457%\n",
      "Epoch: 74, Accuracy: 6.50%                                             \n",
      "  Loss: 25%: 3.993256 50%: 4.172734 75%: 4.347446\n",
      "   Avg: 4.159883\n",
      "  Total Seq Acc: 29.597%\n",
      "    Avg Seq Acc: 54.651%\n",
      "Epoch: 75, Accuracy: 6.61%                                             \n",
      "  Loss: 25%: 3.958025 50%: 4.135107 75%: 4.308427\n",
      "   Avg: 4.125654\n",
      "  Total Seq Acc: 29.609%\n",
      "    Avg Seq Acc: 55.055%\n",
      "Epoch: 76, Accuracy: 6.59%                                             \n",
      "  Loss: 25%: 3.917328 50%: 4.103796 75%: 4.269819\n",
      "   Avg: 4.087300\n",
      "  Total Seq Acc: 29.657%\n",
      "    Avg Seq Acc: 55.217%\n",
      "Epoch: 77, Accuracy: 6.58%                                             \n",
      "  Loss: 25%: 3.879177 50%: 4.067356 75%: 4.242549\n",
      "   Avg: 4.051447\n",
      "  Total Seq Acc: 29.621%\n",
      "    Avg Seq Acc: 55.610%\n",
      "Epoch: 78, Accuracy: 6.58%                                             \n",
      "  Loss: 25%: 3.837713 50%: 4.015896 75%: 4.197536\n",
      "   Avg: 4.012370\n",
      "  Total Seq Acc: 29.621%\n",
      "    Avg Seq Acc: 55.748%\n",
      "Epoch: 79, Accuracy: 6.67%                                             \n",
      "  Loss: 25%: 3.810340 50%: 3.995052 75%: 4.176280\n",
      "   Avg: 3.986131\n",
      "  Total Seq Acc: 29.651%\n",
      "    Avg Seq Acc: 56.044%\n",
      "Epoch: 80, Accuracy: 6.69%                                             \n",
      "  Loss: 25%: 3.760587 50%: 3.945512 75%: 4.129912\n",
      "   Avg: 3.938876\n",
      "  Total Seq Acc: 29.686%\n",
      "    Avg Seq Acc: 56.405%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 4088 # *14 close to 4096\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.6})\n",
    "trainFor(20, target_p50_loss=0.2, target_seq_acc=0.60)\n",
    "# (287mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 10000\n",
      "  Total: 16809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 90000\n",
      "  Total: 96809\n",
      "Epoch: 81, Accuracy: 4.57%                                             \n",
      "  Loss: 25%: 3.732700 50%: 3.915807 75%: 4.088503\n",
      "   Avg: 3.907259\n",
      "  Total Seq Acc: 29.651%\n",
      "    Avg Seq Acc: 56.869%\n",
      "Epoch: 82, Accuracy: 4.59%                                             \n",
      "  Loss: 25%: 3.674026 50%: 3.859215 75%: 4.042680\n",
      "   Avg: 3.849874\n",
      "  Total Seq Acc: 29.651%\n",
      "    Avg Seq Acc: 57.284%\n",
      "Epoch: 83, Accuracy: 4.59%                                             \n",
      "  Loss: 25%: 3.613226 50%: 3.798069 75%: 3.976622\n",
      "   Avg: 3.792179\n",
      "  Total Seq Acc: 29.621%\n",
      "    Avg Seq Acc: 57.726%\n",
      "Epoch: 84, Accuracy: 4.54%                                             \n",
      "  Loss: 25%: 3.542132 50%: 3.738827 75%: 3.919701\n",
      "   Avg: 3.727699\n",
      "  Total Seq Acc: 29.567%\n",
      "    Avg Seq Acc: 58.218%\n",
      "Epoch: 85, Accuracy: 4.53%                                             \n",
      "  Loss: 25%: 3.489605 50%: 3.680619 75%: 3.860891\n",
      "   Avg: 3.671081\n",
      "  Total Seq Acc: 29.562%\n",
      "    Avg Seq Acc: 58.750%\n",
      "Epoch: 86, Accuracy: 4.55%                                             \n",
      "  Loss: 25%: 3.419655 50%: 3.618396 75%: 3.801872\n",
      "   Avg: 3.606837\n",
      "  Total Seq Acc: 29.532%\n",
      "    Avg Seq Acc: 59.166%\n",
      "Epoch: 87, Accuracy: 4.53%                                             \n",
      "  Loss: 25%: 3.365698 50%: 3.555354 75%: 3.742208\n",
      "   Avg: 3.547724\n",
      "  Total Seq Acc: 29.508%\n",
      "    Avg Seq Acc: 59.466%\n",
      "Epoch: 88, Accuracy: 4.53%                                             \n",
      "  Loss: 25%: 3.302626 50%: 3.496680 75%: 3.678548\n",
      "   Avg: 3.486676\n",
      "  Total Seq Acc: 29.484%\n",
      "    Avg Seq Acc: 59.837%\n",
      "Epoch: 89, Accuracy: 4.60%                                             \n",
      "  Loss: 25%: 3.237135 50%: 3.432674 75%: 3.619565\n",
      "   Avg: 3.425660\n",
      "  Total Seq Acc: 29.460%\n",
      "    Avg Seq Acc: 60.369%\n",
      "Epoch: 90, Accuracy: 4.54%                                             \n",
      "  Loss: 25%: 3.177437 50%: 3.368291 75%: 3.557559\n",
      "   Avg: 3.361821\n",
      "  Total Seq Acc: 29.401%\n",
      "    Avg Seq Acc: 60.775%\n",
      "Epoch: 91, Accuracy: 4.55%                                             \n",
      "  Loss: 25%: 3.109714 50%: 3.306365 75%: 3.494098\n",
      "   Avg: 3.301189\n",
      "  Total Seq Acc: 29.335%\n",
      "    Avg Seq Acc: 61.437%\n",
      "Epoch: 92, Accuracy: 4.59%                                             \n",
      "  Loss: 25%: 3.062381 50%: 3.251327 75%: 3.435799\n",
      "   Avg: 3.244271\n",
      "  Total Seq Acc: 29.306%\n",
      "    Avg Seq Acc: 61.574%\n",
      "Epoch: 93, Accuracy: 4.64%                                             \n",
      "  Loss: 25%: 2.996714 50%: 3.176980 75%: 3.371019\n",
      "   Avg: 3.178843\n",
      "  Total Seq Acc: 29.353%\n",
      "    Avg Seq Acc: 62.033%\n",
      "Epoch: 94, Accuracy: 4.71%                                             \n",
      "  Loss: 25%: 2.937175 50%: 3.126325 75%: 3.314143\n",
      "   Avg: 3.122422\n",
      "  Total Seq Acc: 29.312%\n",
      "    Avg Seq Acc: 62.274%\n",
      "Epoch: 95, Accuracy: 4.58%                                             \n",
      "  Loss: 25%: 2.879818 50%: 3.071250 75%: 3.257771\n",
      "   Avg: 3.064600\n",
      "  Total Seq Acc: 29.276%\n",
      "    Avg Seq Acc: 62.830%\n",
      "Epoch: 96, Accuracy: 4.68%                                             \n",
      "  Loss: 25%: 2.823712 50%: 3.013954 75%: 3.202656\n",
      "   Avg: 3.009824\n",
      "  Total Seq Acc: 29.306%\n",
      "    Avg Seq Acc: 63.389%\n",
      "Epoch: 97, Accuracy: 4.68%                                             \n",
      "  Loss: 25%: 2.767589 50%: 2.958042 75%: 3.140119\n",
      "   Avg: 2.953923\n",
      "  Total Seq Acc: 29.306%\n",
      "    Avg Seq Acc: 63.737%\n",
      "Epoch: 98, Accuracy: 4.74%                                             \n",
      "  Loss: 25%: 2.711817 50%: 2.902988 75%: 3.096267\n",
      "   Avg: 2.902680\n",
      "  Total Seq Acc: 29.246%\n",
      "    Avg Seq Acc: 64.069%\n",
      "Epoch: 99, Accuracy: 4.69%                                             \n",
      "  Loss: 25%: 2.666791 50%: 2.856939 75%: 3.036352\n",
      "   Avg: 2.850777\n",
      "  Total Seq Acc: 29.252%\n",
      "    Avg Seq Acc: 64.822%\n",
      "Epoch: 100, Accuracy: 4.72%                                             \n",
      "  Loss: 25%: 2.622393 50%: 2.808104 75%: 2.994466\n",
      "   Avg: 2.805886\n",
      "  Total Seq Acc: 29.240%\n",
      "    Avg Seq Acc: 64.541%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 4088 # *14 close to 4096\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(20, target_p50_loss=0.2, target_seq_acc=0.75)\n",
    "# (414mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 10000\n",
      "  Total: 16809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 90000\n",
      "  Total: 96809\n",
      "Epoch: 101, Accuracy: 4.76%                                             \n",
      "  Loss: 25%: 2.582887 50%: 2.773144 75%: 2.960040\n",
      "   Avg: 2.768915\n",
      "  Total Seq Acc: 29.252%\n",
      "    Avg Seq Acc: 65.546%\n",
      "Epoch: 102, Accuracy: 4.79%                                             \n",
      "  Loss: 25%: 2.531624 50%: 2.719196 75%: 2.908400\n",
      "   Avg: 2.718570\n",
      "  Total Seq Acc: 29.240%\n",
      "    Avg Seq Acc: 66.019%\n",
      "Epoch: 103, Accuracy: 4.79%                                             \n",
      "  Loss: 25%: 2.490860 50%: 2.673386 75%: 2.860445\n",
      "   Avg: 2.675337\n",
      "  Total Seq Acc: 29.234%\n",
      "    Avg Seq Acc: 65.966%\n",
      "Epoch: 104, Accuracy: 4.84%                                             \n",
      "  Loss: 25%: 2.450328 50%: 2.630445 75%: 2.810037\n",
      "   Avg: 2.632108\n",
      "  Total Seq Acc: 29.258%\n",
      "    Avg Seq Acc: 66.305%\n",
      "Epoch: 105, Accuracy: 4.80%                                             \n",
      "  Loss: 25%: 2.408918 50%: 2.595450 75%: 2.775468\n",
      "   Avg: 2.596293\n",
      "  Total Seq Acc: 29.228%\n",
      "    Avg Seq Acc: 66.572%\n",
      "Epoch: 106, Accuracy: 4.87%                                             \n",
      "  Loss: 25%: 2.378685 50%: 2.562530 75%: 2.741190\n",
      "   Avg: 2.560061\n",
      "  Total Seq Acc: 29.216%\n",
      "    Avg Seq Acc: 67.073%\n",
      "Epoch: 107, Accuracy: 4.87%                                             \n",
      "  Loss: 25%: 2.345266 50%: 2.524939 75%: 2.703465\n",
      "   Avg: 2.523668\n",
      "  Total Seq Acc: 29.169%\n",
      "    Avg Seq Acc: 67.320%\n",
      "Epoch: 108, Accuracy: 4.92%                                             \n",
      "  Loss: 25%: 2.308298 50%: 2.486377 75%: 2.662286\n",
      "   Avg: 2.485948\n",
      "  Total Seq Acc: 29.205%\n",
      "    Avg Seq Acc: 67.615%\n",
      "Epoch: 109, Accuracy: 4.83%                                             \n",
      "  Loss: 25%: 2.274045 50%: 2.452656 75%: 2.637370\n",
      "   Avg: 2.453636\n",
      "  Total Seq Acc: 29.211%\n",
      "    Avg Seq Acc: 68.021%\n",
      "Epoch: 110, Accuracy: 4.91%                                             \n",
      "  Loss: 25%: 2.239380 50%: 2.422572 75%: 2.597214\n",
      "   Avg: 2.421732\n",
      "  Total Seq Acc: 29.175%\n",
      "    Avg Seq Acc: 68.377%\n",
      "> KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 4088 # *14 close to 4096\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(20, target_p50_loss=0.2, target_seq_acc=0.8)\n",
    "# (207mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 50000\n",
      "  Total: 56809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 225000\n",
      "  Total: 231809\n",
      "Epoch: 111, Accuracy: 2.34%                                             \n",
      "  Loss: 25%: 2.276829 50%: 2.457360 75%: 2.641550\n",
      "   Avg: 2.461111\n",
      "  Total Seq Acc: 9.407%\n",
      "    Avg Seq Acc: 58.416%\n",
      "Epoch: 112, Accuracy: 2.36%                                             \n",
      "  Loss: 25%: 2.206423 50%: 2.379490 75%: 2.559779\n",
      "   Avg: 2.384682\n",
      "  Total Seq Acc: 9.449%\n",
      "    Avg Seq Acc: 58.906%\n",
      "Epoch: 113, Accuracy: 2.38%                                             \n",
      "  Loss: 25%: 2.157212 50%: 2.328168 75%: 2.504146\n",
      "   Avg: 2.331942\n",
      "  Total Seq Acc: 9.481%\n",
      "    Avg Seq Acc: 59.789%\n",
      "Epoch: 114, Accuracy: 2.42%                                             \n",
      "  Loss: 25%: 2.100640 50%: 2.272418 75%: 2.444943\n",
      "   Avg: 2.277403\n",
      "  Total Seq Acc: 9.484%\n",
      "    Avg Seq Acc: 60.633%\n",
      "Epoch: 115, Accuracy: 2.48%                                             \n",
      "  Loss: 25%: 2.047293 50%: 2.212603 75%: 2.390631\n",
      "   Avg: 2.223183\n",
      "  Total Seq Acc: 9.500%\n",
      "    Avg Seq Acc: 61.151%\n",
      "Epoch: 116, Accuracy: 2.51%                                             \n",
      "  Loss: 25%: 1.996575 50%: 2.161652 75%: 2.336312\n",
      "   Avg: 2.170031\n",
      "  Total Seq Acc: 9.634%\n",
      "    Avg Seq Acc: 62.200%\n",
      "Epoch: 117, Accuracy: 2.55%                                             \n",
      "  Loss: 25%: 1.943973 50%: 2.113680 75%: 2.287021\n",
      "   Avg: 2.119863\n",
      "  Total Seq Acc: 9.669%\n",
      "    Avg Seq Acc: 62.656%\n",
      "Epoch: 118, Accuracy: 2.58%                                             \n",
      "  Loss: 25%: 1.898674 50%: 2.062693 75%: 2.234684\n",
      "   Avg: 2.071649\n",
      "  Total Seq Acc: 9.773%\n",
      "    Avg Seq Acc: 63.311%\n",
      "Epoch: 119, Accuracy: 2.61%                                             \n",
      "  Loss: 25%: 1.850266 50%: 2.010956 75%: 2.186982\n",
      "   Avg: 2.023944\n",
      "  Total Seq Acc: 9.815%\n",
      "    Avg Seq Acc: 64.005%\n",
      "Epoch: 120, Accuracy: 2.66%                                             \n",
      "  Loss: 25%: 1.810292 50%: 1.969846 75%: 2.141261\n",
      "   Avg: 1.980639\n",
      "  Total Seq Acc: 9.993%\n",
      "    Avg Seq Acc: 65.280%\n",
      "Epoch: 121, Accuracy: 2.71%                                             \n",
      "  Loss: 25%: 1.768012 50%: 1.928758 75%: 2.095697\n",
      "   Avg: 1.939012\n",
      "  Total Seq Acc: 10.037%\n",
      "    Avg Seq Acc: 65.917%\n",
      "Epoch: 122, Accuracy: 2.78%                                             \n",
      "  Loss: 25%: 1.727332 50%: 1.886460 75%: 2.054953\n",
      "   Avg: 1.898548\n",
      "  Total Seq Acc: 10.044%\n",
      "    Avg Seq Acc: 66.526%\n",
      "Epoch: 123, Accuracy: 2.80%                                             \n",
      "  Loss: 25%: 1.691013 50%: 1.846782 75%: 2.012347\n",
      "   Avg: 1.860010\n",
      "  Total Seq Acc: 10.153%\n",
      "    Avg Seq Acc: 67.012%\n",
      "Epoch: 124, Accuracy: 2.81%                                             \n",
      "  Loss: 25%: 1.665340 50%: 1.821267 75%: 1.987421\n",
      "   Avg: 1.834360\n",
      "  Total Seq Acc: 10.194%\n",
      "    Avg Seq Acc: 67.555%\n",
      "Epoch: 125, Accuracy: 2.88%                                             \n",
      "  Loss: 25%: 1.624811 50%: 1.776395 75%: 1.942218\n",
      "   Avg: 1.790853\n",
      "  Total Seq Acc: 10.321%\n",
      "    Avg Seq Acc: 68.342%\n",
      "Epoch: 126, Accuracy: 2.92%                                             \n",
      "  Loss: 25%: 1.593555 50%: 1.744505 75%: 1.907752\n",
      "   Avg: 1.759509\n",
      "  Total Seq Acc: 10.261%\n",
      "    Avg Seq Acc: 68.471%\n",
      "Epoch: 127, Accuracy: 3.01%                                             \n",
      "  Loss: 25%: 1.564867 50%: 1.714490 75%: 1.874775\n",
      "   Avg: 1.728149\n",
      "  Total Seq Acc: 10.231%\n",
      "    Avg Seq Acc: 68.648%\n",
      "Epoch: 128, Accuracy: 2.97%                                             \n",
      "  Loss: 25%: 1.535596 50%: 1.686345 75%: 1.848891\n",
      "   Avg: 1.702002\n",
      "  Total Seq Acc: 10.384%\n",
      "    Avg Seq Acc: 69.154%\n",
      "Epoch: 129, Accuracy: 3.07%                                             \n",
      "  Loss: 25%: 1.507413 50%: 1.656440 75%: 1.816297\n",
      "   Avg: 1.673159\n",
      "  Total Seq Acc: 10.440%\n",
      "    Avg Seq Acc: 69.461%\n",
      "Epoch: 130, Accuracy: 3.09%                                             \n",
      "  Loss: 25%: 1.487182 50%: 1.633095 75%: 1.793639\n",
      "   Avg: 1.650341\n",
      "  Total Seq Acc: 10.380%\n",
      "    Avg Seq Acc: 68.943%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 4088 # *14 close to 4096\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.45})\n",
    "trainFor(20, target_p50_loss=0.2, target_seq_acc=0.7)\n",
    "# (910mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 50000\n",
      "  Total: 56809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 450000\n",
      "  Total: 456809\n",
      "Epoch: 131, Accuracy: 2.23%                                             \n",
      "  Loss: 25%: 1.521034 50%: 1.679262 75%: 1.864767\n",
      "   Avg: 1.712413\n",
      "  Total Seq Acc: 10.402%\n",
      "    Avg Seq Acc: 69.580%\n",
      "Epoch: 132, Accuracy: 2.27%                                             \n",
      "  Loss: 25%: 1.457995 50%: 1.602164 75%: 1.763342\n",
      "   Avg: 1.622421\n",
      "  Total Seq Acc: 10.562%\n",
      "    Avg Seq Acc: 70.585%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(5, target_p50_loss=0.2, target_seq_acc=0.7)\n",
    "# (190mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 50000\n",
      "  Total: 56809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 450000\n",
      "  Total: 456809\n",
      "Epoch: 133, Accuracy: 2.28%                                             \n",
      "  Loss: 25%: 1.490670 50%: 1.647786 75%: 1.826489\n",
      "   Avg: 1.674148\n",
      "  Total Seq Acc: 10.500%\n",
      "    Avg Seq Acc: 70.198%\n",
      "Epoch: 134, Accuracy: 2.30%                                             \n",
      "  Loss: 25%: 1.435652 50%: 1.579442 75%: 1.736099\n",
      "   Avg: 1.597088\n",
      "  Total Seq Acc: 10.597%\n",
      "    Avg Seq Acc: 70.851%\n",
      "Epoch: 135, Accuracy: 2.37%                                             \n",
      "  Loss: 25%: 1.417854 50%: 1.559237 75%: 1.719589\n",
      "   Avg: 1.580035\n",
      "  Total Seq Acc: 10.622%\n",
      "    Avg Seq Acc: 71.207%\n",
      "Epoch: 136, Accuracy: 2.40%                                             \n",
      "  Loss: 25%: 1.399602 50%: 1.541654 75%: 1.697758\n",
      "   Avg: 1.561598\n",
      "  Total Seq Acc: 10.627%\n",
      "    Avg Seq Acc: 71.203%\n",
      "Epoch: 137, Accuracy: 2.44%                                             \n",
      "  Loss: 25%: 1.383282 50%: 1.522269 75%: 1.679267\n",
      "   Avg: 1.544239\n",
      "  Total Seq Acc: 10.769%\n",
      "    Avg Seq Acc: 71.764%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(5, target_p50_loss=0.2, target_seq_acc=0.8)\n",
    "# (472mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 50000\n",
      "  Total: 56809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 450000\n",
      "  Total: 456809\n",
      "Epoch: 138, Accuracy: 2.38%                                             \n",
      "  Loss: 25%: 1.403795 50%: 1.553975 75%: 1.726176\n",
      "   Avg: 1.579655\n",
      "  Total Seq Acc: 10.694%\n",
      "    Avg Seq Acc: 71.961%\n",
      "Epoch: 139, Accuracy: 2.44%                                             \n",
      "  Loss: 25%: 1.356656 50%: 1.497774 75%: 1.653503\n",
      "   Avg: 1.517331\n",
      "  Total Seq Acc: 10.750%\n",
      "    Avg Seq Acc: 71.842%\n",
      "Epoch: 140, Accuracy: 2.49%                                             \n",
      "  Loss: 25%: 1.343703 50%: 1.479851 75%: 1.636741\n",
      "   Avg: 1.502873\n",
      "  Total Seq Acc: 10.766%\n",
      "    Avg Seq Acc: 72.292%\n",
      "Epoch: 141, Accuracy: 2.51%                                             \n",
      "  Loss: 25%: 1.327164 50%: 1.465816 75%: 1.620993\n",
      "   Avg: 1.487350\n",
      "  Total Seq Acc: 10.778%\n",
      "    Avg Seq Acc: 71.991%\n",
      "Epoch: 142, Accuracy: 2.55%                                             \n",
      "  Loss: 25%: 1.311608 50%: 1.448447 75%: 1.602099\n",
      "   Avg: 1.470500\n",
      "  Total Seq Acc: 10.960%\n",
      "    Avg Seq Acc: 72.587%\n",
      "Epoch: 143, Accuracy: 2.59%                                             \n",
      "  Loss: 25%: 1.295611 50%: 1.430909 75%: 1.586983\n",
      "   Avg: 1.454976\n",
      "  Total Seq Acc: 10.829%\n",
      "    Avg Seq Acc: 72.491%\n",
      "Epoch: 144, Accuracy: 2.63%                                             \n",
      "  Loss: 25%: 1.280524 50%: 1.414572 75%: 1.567500\n",
      "   Avg: 1.438181\n",
      "  Total Seq Acc: 10.995%\n",
      "    Avg Seq Acc: 73.489%\n",
      "Epoch: 145, Accuracy: 2.64%                                             \n",
      "  Loss: 25%: 1.268385 50%: 1.402360 75%: 1.556261\n",
      "   Avg: 1.424707\n",
      "  Total Seq Acc: 10.850%\n",
      "    Avg Seq Acc: 72.644%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(8, target_p50_loss=1.0, target_seq_acc=0.8)\n",
    "# (760mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 50000\n",
      "  Total: 56809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 450000\n",
      "  Total: 456809\n",
      "Epoch: 146, Accuracy: 2.60%                                             \n",
      "  Loss: 25%: 1.300828 50%: 1.450290 75%: 1.629443\n",
      "   Avg: 1.490706\n",
      "  Total Seq Acc: 10.868%\n",
      "    Avg Seq Acc: 72.612%\n",
      "Epoch: 147, Accuracy: 2.67%                                             \n",
      "  Loss: 25%: 1.243615 50%: 1.377183 75%: 1.529420\n",
      "   Avg: 1.400512\n",
      "  Total Seq Acc: 11.039%\n",
      "    Avg Seq Acc: 73.415%\n",
      "Epoch: 148, Accuracy: 2.69%                                             \n",
      "  Loss: 25%: 1.233071 50%: 1.366198 75%: 1.516507\n",
      "   Avg: 1.389540\n",
      "  Total Seq Acc: 11.111%\n",
      "    Avg Seq Acc: 73.853%\n",
      "Epoch: 149, Accuracy: 2.71%                                             \n",
      "  Loss: 25%: 1.225038 50%: 1.355762 75%: 1.507573\n",
      "   Avg: 1.380100\n",
      "  Total Seq Acc: 11.090%\n",
      "    Avg Seq Acc: 73.963%\n",
      "Epoch: 150, Accuracy: 2.76%                                             \n",
      "  Loss: 25%: 1.211282 50%: 1.344244 75%: 1.496817\n",
      "   Avg: 1.367571\n",
      "  Total Seq Acc: 11.012%\n",
      "    Avg Seq Acc: 73.829%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(5, target_p50_loss=1.0, target_seq_acc=0.8)\n",
    "# (471mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 50000\n",
      "  Total: 56809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 450000\n",
      "  Total: 456809\n",
      "Epoch: 146, Accuracy: 2.58%                                             \n",
      "  Loss: 25%: 1.306898 50%: 1.460468 75%: 1.655614\n",
      "   Avg: 1.516379\n",
      "  Total Seq Acc: 11.018%\n",
      "    Avg Seq Acc: 73.374%\n",
      "Epoch: 147, Accuracy: 2.69%                                             \n",
      "  Loss: 25%: 1.245178 50%: 1.380684 75%: 1.530738\n",
      "   Avg: 1.402660\n",
      "  Total Seq Acc: 10.984%\n",
      "    Avg Seq Acc: 73.345%\n",
      "Epoch: 148, Accuracy: 2.70%                                             \n",
      "  Loss: 25%: 1.235114 50%: 1.368473 75%: 1.519865\n",
      "   Avg: 1.392687\n",
      "  Total Seq Acc: 11.002%\n",
      "    Avg Seq Acc: 73.712%\n",
      "Epoch: 149, Accuracy: 2.73%                                             \n",
      "  Loss: 25%: 1.224935 50%: 1.357892 75%: 1.509347\n",
      "   Avg: 1.380911\n",
      "  Total Seq Acc: 11.109%\n",
      "    Avg Seq Acc: 73.988%\n",
      "Epoch: 150, Accuracy: 2.77%                                             \n",
      "  Loss: 25%: 1.214761 50%: 1.346204 75%: 1.496404\n",
      "   Avg: 1.369344\n",
      "  Total Seq Acc: 11.032%\n",
      "    Avg Seq Acc: 74.024%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(5, target_p50_loss=1.0, target_seq_acc=0.75)\n",
    "# (473mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 50000\n",
      "  Total: 56809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 450000\n",
      "  Total: 456809\n",
      "Epoch: 146, Accuracy: 1.98%                                             \n",
      "  Loss: 25%: 1.880580 50%: 2.172355 75%: 2.669309\n",
      "   Avg: 2.395109\n",
      "  Total Seq Acc: 9.453%\n",
      "    Avg Seq Acc: 65.815%\n",
      "Epoch: 147, Accuracy: 2.14%                                             \n",
      "  Loss: 25%: 1.417541 50%: 1.556936 75%: 1.704864\n",
      "   Avg: 1.571578\n",
      "  Total Seq Acc: 10.039%\n",
      "    Avg Seq Acc: 71.823%\n",
      "Epoch: 148, Accuracy: 2.34%                                             \n",
      "  Loss: 25%: 1.283669 50%: 1.408078 75%: 1.546098\n",
      "   Avg: 1.429610\n",
      "  Total Seq Acc: 10.164%\n",
      "    Avg Seq Acc: 73.131%\n",
      "Epoch: 149, Accuracy: 2.45%                                             \n",
      "  Loss: 25%: 1.220210 50%: 1.345649 75%: 1.486402\n",
      "   Avg: 1.367570\n",
      "  Total Seq Acc: 10.606%\n",
      "    Avg Seq Acc: 75.726%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(5, target_p50_loss=1.0, target_seq_acc=0.75)\n",
    "# (380mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 50000\n",
      "  Total: 56809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 450000\n",
      "  Total: 456809\n",
      "Epoch: 150, Accuracy: 2.52%                                             \n",
      "  Loss: 25%: 1.173243 50%: 1.296289 75%: 1.433404\n",
      "   Avg: 1.319219\n",
      "  Total Seq Acc: 10.685%\n",
      "    Avg Seq Acc: 76.539%\n",
      "Epoch: 151, Accuracy: 2.57%                                             \n",
      "  Loss: 25%: 1.140962 50%: 1.263296 75%: 1.400819\n",
      "   Avg: 1.286998\n",
      "  Total Seq Acc: 10.835%\n",
      "    Avg Seq Acc: 77.294%\n",
      "Epoch: 152, Accuracy: 2.63%                                             \n",
      "  Loss: 25%: 1.108131 50%: 1.230870 75%: 1.367448\n",
      "   Avg: 1.255032\n",
      "  Total Seq Acc: 10.919%\n",
      "    Avg Seq Acc: 78.192%\n",
      "Epoch: 153, Accuracy: 2.71%                                             \n",
      "  Loss: 25%: 1.084787 50%: 1.205648 75%: 1.342836\n",
      "   Avg: 1.230732\n",
      "  Total Seq Acc: 11.062%\n",
      "    Avg Seq Acc: 78.694%\n",
      "Epoch: 154, Accuracy: 2.74%                                             \n",
      "  Loss: 25%: 1.060282 50%: 1.179209 75%: 1.316372\n",
      "   Avg: 1.205567\n",
      "  Total Seq Acc: 11.123%\n",
      "    Avg Seq Acc: 79.054%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(5, target_p50_loss=1.0, target_seq_acc=0.80)\n",
    "# (491mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 50000\n",
      "  Total: 56809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 450000\n",
      "  Total: 456809\n",
      "Epoch: 155, Accuracy: 2.61%                                             \n",
      "  Loss: 25%: 1.118059 50%: 1.267285 75%: 1.468731\n",
      "   Avg: 1.357771\n",
      "  Total Seq Acc: 10.947%\n",
      "    Avg Seq Acc: 78.352%\n",
      "Epoch: 156, Accuracy: 2.78%                                             \n",
      "  Loss: 25%: 1.036225 50%: 1.155239 75%: 1.290535\n",
      "   Avg: 1.180834\n",
      "  Total Seq Acc: 11.178%\n",
      "    Avg Seq Acc: 79.604%\n",
      "Epoch: 157, Accuracy: 2.82%                                             \n",
      "  Loss: 25%: 1.021374 50%: 1.140734 75%: 1.279699\n",
      "   Avg: 1.168246\n",
      "  Total Seq Acc: 11.236%\n",
      "    Avg Seq Acc: 79.959%\n",
      "Epoch: 158, Accuracy: 2.86%                                             \n",
      "  Loss: 25%: 1.012528 50%: 1.128791 75%: 1.262950\n",
      "   Avg: 1.155522\n",
      "  Total Seq Acc: 11.326%\n",
      "    Avg Seq Acc: 80.388%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(6, target_p50_loss=1.0, target_seq_acc=0.80)\n",
    "# (380mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 50000\n",
      "  Total: 56809\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - grammar: 450000\n",
      "  Total: 456809\n",
      "Epoch: 159, Accuracy: 2.88%                                             \n",
      "  Loss: 25%: 0.999729 50%: 1.115270 75%: 1.247488\n",
      "   Avg: 1.142749\n",
      "  Total Seq Acc: 11.331%\n",
      "    Avg Seq Acc: 80.665%\n",
      "Epoch: 160, Accuracy: 2.92%                                             \n",
      "  Loss: 25%: 0.983621 50%: 1.100303 75%: 1.237552\n",
      "   Avg: 1.128711\n",
      "  Total Seq Acc: 11.282%\n",
      "    Avg Seq Acc: 80.531%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(160-start_epoch, target_p50_loss=1.0, target_seq_acc=0.90)\n",
    "# (190mins)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
