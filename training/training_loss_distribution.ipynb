{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded facebook/bart-base\n"
     ]
    }
   ],
   "source": [
    "# Init/Load model\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "# Define a directory to save the models\n",
    "SAVE_DIR = '../saved_models'\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "class SimpleBART(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleBART, self).__init__()\n",
    "        if start_epoch > 0:\n",
    "            self.bart = BartForConditionalGeneration.from_pretrained(os.path.join(SAVE_DIR, f'epoch_{start_epoch}'))\n",
    "            print(f'Loaded epoch_{start_epoch}')\n",
    "        else:\n",
    "            self.bart = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "            print('Loaded facebook/bart-base')\n",
    "        self.tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.bart(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "\n",
    "model = SimpleBART().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Raw Datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import csv\n",
    "\n",
    "ACCUMULATION_STEPS = 14\n",
    "BATCH_SIZE = 14 # best performing batch size so far (in execution performance)\n",
    "DATA_SIZE = 0\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=200):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        self.start_token_id = tokenizer.cls_token_id\n",
    "        self.end_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text, tokens = self.data[idx]\n",
    "        \n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=self.max_length)\n",
    "        \n",
    "        # Add start and end tokens and then pad\n",
    "        tokens = [self.start_token_id] + tokens + [self.end_token_id]\n",
    "        tokens_padded = [self.pad_token_id] * self.max_length\n",
    "        tokens_padded[:len(tokens)] = tokens\n",
    "        tokens_padded[len(tokens):] = [self.pad_token_id] * (self.max_length - len(tokens))\n",
    "        \n",
    "        return inputs[\"input_ids\"].squeeze(0), inputs[\"attention_mask\"].squeeze(0), torch.tensor(tokens_padded, dtype=torch.long)\n",
    "\n",
    "\n",
    "def load_data_from_csv(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        data = [(row[0], [int(tok) for tok in row[1].split(\",\")]) for row in reader]\n",
    "\n",
    "    return data\n",
    "\n",
    "def apply_concept(params, validation=False):\n",
    "    global validationLoader\n",
    "    global dataloader\n",
    "    global DATA_SIZE\n",
    "\n",
    "    merged_data = load_data_from_csv(f\"../concept/egg.csv\")\n",
    "    \n",
    "    print(\"Concepts loaded;\")\n",
    "    for file_name, percentage in params.items():\n",
    "        data = load_data_from_csv(f\"../concept/{file_name}.csv\")\n",
    "        cutoff = int(len(data) * percentage)\n",
    "        \n",
    "        if validation:\n",
    "            loaded_data = data[-cutoff:]\n",
    "        else:\n",
    "            loaded_data = data[:cutoff]\n",
    "\n",
    "        print(f\"    - {file_name}: {len(loaded_data)}\")\n",
    "        merged_data.extend(loaded_data)\n",
    "\n",
    "    DATA_SIZE = len(merged_data)\n",
    "    dataset = CustomDataset(merged_data, model.tokenizer)\n",
    "    if validation:\n",
    "        validationLoader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    else:\n",
    "        dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    print(f'  Total: {DATA_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Validator\n",
    "def validate():\n",
    "    EOS_TOKEN_ID = model.tokenizer.eos_token_id\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize counters for accuracy calculation\n",
    "    total_correct_sequences = 0\n",
    "    total_sequences = 0\n",
    "\n",
    "    # Initialize counters for average sequence accuracy within the mask\n",
    "    total_accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input_ids, attention_mask, targets) in enumerate(validationLoader):\n",
    "            input_ids, attention_mask, targets = input_ids.to(device), attention_mask.to(device), targets.to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Identify where the EOS token is in the target sequence\n",
    "            eos_positions = (targets == EOS_TOKEN_ID).cumsum(dim=1).type(torch.bool)\n",
    "            mask = ~eos_positions | (targets == EOS_TOKEN_ID)\n",
    "\n",
    "            _, predicted = logits.max(2)\n",
    "            correct_sequences = ((predicted == targets) | ~mask).all(dim=1).float().sum().item()\n",
    "            total_sequences += targets.size(0)\n",
    "            total_correct_sequences += correct_sequences\n",
    "\n",
    "            # Compute the accuracy for each sequence\n",
    "            correct_tokens_per_sequence = ((predicted == targets) & mask).float().sum(dim=1)\n",
    "            total_tokens_per_sequence = mask.float().sum(dim=1)\n",
    "            total_accuracy += (correct_tokens_per_sequence / total_tokens_per_sequence).sum().item()\n",
    "\n",
    "    # Compute and print the accuracy for the entire validation dataset\n",
    "    validation_accuracy = total_correct_sequences / total_sequences\n",
    "    print(f\"  Total Seq Acc: {validation_accuracy*100:.3f}%\")\n",
    "    avg_accuracy = total_accuracy / total_sequences\n",
    "    print(f\"    Avg Seq Acc: {avg_accuracy*100:.3f}%\")\n",
    "\n",
    "    return avg_accuracy, validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup trainer\n",
    "def save_model():\n",
    "    global start_epoch\n",
    "    model_save_path = os.path.join(SAVE_DIR, f'epoch_{start_epoch}')\n",
    "    model.bart.save_pretrained(model_save_path)\n",
    "\n",
    "def trainFor(num_epochs, target_loss=0, target_p50_loss=0, target_acc=1.0, target_seq_acc=1.0):\n",
    "    global start_epoch\n",
    "\n",
    "    EOS_TOKEN_ID = model.tokenizer.eos_token_id\n",
    "    acc_batch = int(ACCUMULATION_STEPS / BATCH_SIZE)\n",
    "    total_batches = len(dataloader)\n",
    "\n",
    "    for epoch in range(start_epoch+1, start_epoch+num_epochs+1):\n",
    "        start_epoch = epoch\n",
    "        model.train()\n",
    "\n",
    "        # Resetting the accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Initialize counters for accuracy calculation\n",
    "        total_correct_sequences = 0\n",
    "        total_sequences = 0\n",
    "        cumulative_loss = 0.0\n",
    "\n",
    "        # Initialize list to store batch losses\n",
    "        batch_losses = []\n",
    "\n",
    "        for batch_idx, (input_ids, attention_mask, targets) in enumerate(dataloader):\n",
    "\n",
    "            input_ids, attention_mask, targets = input_ids.to(device), attention_mask.to(device), targets.to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Identify where the EOS token is in the target sequence\n",
    "            eos_positions = (targets == EOS_TOKEN_ID).cumsum(dim=1).type(torch.bool)\n",
    "            mask = ~eos_positions | (targets == EOS_TOKEN_ID)\n",
    "\n",
    "            # Apply mask to filter out tokens after the EOS token for loss computation\n",
    "            active_loss = mask.view(-1).bool()\n",
    "            active_logits = logits.view(-1, logits.size(-1))[active_loss]\n",
    "            active_labels = targets.view(-1)[active_loss]\n",
    "            loss = criterion(active_logits, active_labels)\n",
    "\n",
    "            _, predicted = logits.max(2)\n",
    "            correct_sequences = ((predicted == targets) | ~mask).all(dim=1).float().sum().item()\n",
    "            total_sequences += targets.size(0)\n",
    "            total_correct_sequences += correct_sequences\n",
    "\n",
    "            # Accumulate the gradients\n",
    "            loss.backward()\n",
    "            loss_val = loss.item()\n",
    "\n",
    "            cumulative_loss += loss_val\n",
    "            batch_losses.append(loss_val)\n",
    "\n",
    "            isLast = batch_idx == len(dataloader) - 1\n",
    "\n",
    "            # Only perform an optimization step every ACCUMULATION_STEPS\n",
    "            if isLast or batch_idx % acc_batch == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            print(f\"\\rEpoch: {epoch}, Batch: {batch_idx} of {total_batches}, loss: {loss_val:.6f}      \", end='')\n",
    "\n",
    "\n",
    "        # Compute and print the accuracy for the entire epoch\n",
    "        epoch_accuracy = total_correct_sequences / total_sequences\n",
    "        cumulative_loss = cumulative_loss / len(batch_losses)\n",
    "        p25_loss = np.percentile(batch_losses, 25)\n",
    "        p50_loss = np.percentile(batch_losses, 50)\n",
    "        p75_loss = np.percentile(batch_losses, 75)\n",
    "        print(f\"\\rEpoch: {epoch}, Accuracy: {epoch_accuracy*100:.2f}%                                             \")\n",
    "        print(f\"  Loss: 25%: {p25_loss:.6f} 50%: {p50_loss:.6f} 75%: {p75_loss:.6f}\\n   Avg: {cumulative_loss:.6f}\")\n",
    "\n",
    "        # Write loss values to loss.csv\n",
    "        percentiles = [np.percentile(batch_losses, i) for i in range(101)]\n",
    "        with open('loss.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([epoch] + percentiles)\n",
    "\n",
    "        if epoch % 10 == 0: # Save the model\n",
    "            save_model()\n",
    "\n",
    "        seq_acc, total_acc = validate()\n",
    "\n",
    "        if total_acc >= target_acc:\n",
    "            break\n",
    "        if cumulative_loss <= target_loss:\n",
    "            break\n",
    "        if p50_loss <= target_p50_loss:\n",
    "            break\n",
    "\n",
    "        if seq_acc >= target_seq_acc:\n",
    "            break\n",
    "\n",
    "    # Make sure last epoch is always saved\n",
    "    save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 3122\n",
      "  Total: 9931\n",
      "Epoch: 1, Accuracy: 0.00%                                             \n",
      "  Loss: 25%: 4.403065 50%: 4.849018 75%: 5.296900\n",
      "   Avg: 4.866282\n",
      "  Total Seq Acc: 0.004%\n",
      "    Avg Seq Acc: 39.869%\n",
      "Epoch: 2, Accuracy: 0.04%                                             \n",
      "  Loss: 25%: 4.114165 50%: 4.543126 75%: 4.914825\n",
      "   Avg: 4.488807\n",
      "  Total Seq Acc: 0.000%\n",
      "    Avg Seq Acc: 39.873%\n",
      "Epoch: 3, Accuracy: 0.04%                                             \n",
      "  Loss: 25%: 4.032996 50%: 4.430487 75%: 4.820580\n",
      "   Avg: 4.396551\n",
      "  Total Seq Acc: 0.076%\n",
      "    Avg Seq Acc: 39.906%\n",
      "Epoch: 4, Accuracy: 0.06%                                             \n",
      "  Loss: 25%: 3.972137 50%: 4.378263 75%: 4.781254\n",
      "   Avg: 4.345113\n",
      "  Total Seq Acc: 0.120%\n",
      "    Avg Seq Acc: 39.934%\n",
      "Epoch: 5, Accuracy: 0.12%                                             \n",
      "  Loss: 25%: 3.932351 50%: 4.367048 75%: 4.685833\n",
      "   Avg: 4.293642\n",
      "  Total Seq Acc: 0.299%\n",
      "    Avg Seq Acc: 40.057%\n",
      "Epoch: 6, Accuracy: 0.37%                                             \n",
      "  Loss: 25%: 3.837589 50%: 4.228431 75%: 4.601477\n",
      "   Avg: 4.183411\n",
      "  Total Seq Acc: 0.945%\n",
      "    Avg Seq Acc: 40.459%\n",
      "Epoch: 7, Accuracy: 1.64%                                             \n",
      "  Loss: 25%: 3.571904 50%: 4.009486 75%: 4.325815\n",
      "   Avg: 3.957460\n",
      "  Total Seq Acc: 3.233%\n",
      "    Avg Seq Acc: 42.656%\n",
      "Epoch: 8, Accuracy: 5.18%                                             \n",
      "  Loss: 25%: 3.171680 50%: 3.612419 75%: 3.961515\n",
      "   Avg: 3.558381\n",
      "  Total Seq Acc: 7.301%\n",
      "    Avg Seq Acc: 48.088%\n",
      "Epoch: 9, Accuracy: 10.70%                                             \n",
      "  Loss: 25%: 2.747878 50%: 3.077505 75%: 3.433291\n",
      "   Avg: 3.070574\n",
      "  Total Seq Acc: 12.099%\n",
      "    Avg Seq Acc: 55.879%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = BATCH_SIZE # pure memorisation so accumulation won't help\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.02})\n",
    "trainFor(50, target_seq_acc=0.50)\n",
    "# (34mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 6245\n",
      "  Total: 13054\n",
      "Epoch: 10, Accuracy: 13.81%                                             \n",
      "  Loss: 25%: 2.656691 50%: 2.988907 75%: 3.271646\n",
      "   Avg: 2.973416\n",
      "  Total Seq Acc: 19.721%\n",
      "    Avg Seq Acc: 68.222%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = BATCH_SIZE # pure memorisation so accumulation won't help\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.04})\n",
    "trainFor(50, target_seq_acc=0.60)\n",
    "# (5mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 9368\n",
      "  Total: 16177\n",
      "Epoch: 11, Accuracy: 17.17%                                             \n",
      "  Loss: 25%: 2.074187 50%: 2.373098 75%: 2.669538\n",
      "   Avg: 2.376195\n",
      "  Total Seq Acc: 27.387%\n",
      "    Avg Seq Acc: 76.537%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 28 # *14 close to 32\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.06})\n",
    "trainFor(50, target_seq_acc=0.65)\n",
    "# (5mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aiming for:\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\frac{unique}{tokens} &= \\frac{4174}{6808} = 61.31\\%  & \\text{sign pairs to text only used once} \\\\\n",
    "  \\frac{text}{tokens}   &= \\frac{5342}{6808}  = 78.47\\% & \\text{sign pairs to text unique text} \\\\\n",
    "  & & \\text{unique meaning the text is only used for one tokenID}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "i.e. there are six different signs which can be used for \"present\"  \n",
    "which means we're actually aiming for $96\\%$ effective accuracy $\\frac{75\\%}{78\\%}$\n",
    "\n",
    "But we don't want to over-fit either  \n",
    "Hence why we slowly introduce new concepts while still memorising vocabulary\n",
    "\n",
    "`target_seq_acc` includes the `EOS` token, which we of course we want to be right\n",
    "So our target should be $\\frac{61.31\\% + 100\\%}{2} = 80.65\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 70 # *14 close to 64\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.08})\n",
    "trainFor(50, target_seq_acc=0.80655)\n",
    "# (mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pure memorisation is over, as the vocabulary has been sufficiently learnt  \n",
    "While it's not perfect, it will improve further over the later training, as the vocab remains in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 1022 # *14 close to 1024\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.225})\n",
    "trainFor(50, target_seq_acc=0.6)\n",
    "# (mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break down of validation per concept\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 1022 # *14 close to 1024\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.45})\n",
    "trainFor(50, target_seq_acc=0.7)\n",
    "# (mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model saved correctly\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 1022 # *14 close to 1024\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.9})\n",
    "trainFor(50, target_seq_acc=0.75)\n",
    "# (mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 1022 # *14 close to 1024\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.9})\n",
    "trainFor(50, target_p50_loss=0.2, target_seq_acc=0.90)\n",
    "# (31mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 4088 # *14 close to 4096\n",
    "apply_concept({\"vocabulary\": 1.0, \"word-masking\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"word-masking\": 0.45})\n",
    "trainFor(20, target_p50_loss=0.2, target_seq_acc=0.70)\n",
    "# (106mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 4088 # *14 close to 4096\n",
    "apply_concept({\"vocabulary\": 1.0, \"word-masking\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"word-masking\": 0.9})\n",
    "trainFor(20, target_p50_loss=0.2, target_seq_acc=0.9)\n",
    "# (151mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopped early, because the new samples are so much longer than the noise, the correct use of the EOS token isn't skewing the `avg seq acc` as much, hence we want to stop closer to our $78.47\\%$ accuracy estimate from before\n",
    "\n",
    "Taking this estimated maximum possible accuracy into account we have currently obtained a $\\frac{75.416\\%}{78.47\\%} = 96.12\\%$ accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 4088 # *14 close to 4096\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.50})\n",
    "trainFor(20, target_p50_loss=0.2, target_seq_acc=0.50)\n",
    "# (100mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 4088 # *14 close to 4096\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.6})\n",
    "trainFor(20, target_p50_loss=0.2, target_seq_acc=0.60)\n",
    "# (287mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 4088 # *14 close to 4096\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(20, target_p50_loss=0.2, target_seq_acc=0.75)\n",
    "# (414mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 4088 # *14 close to 4096\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(20, target_p50_loss=0.2, target_seq_acc=0.8)\n",
    "# (207mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 4088 # *14 close to 4096\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.45})\n",
    "trainFor(20, target_p50_loss=0.2, target_seq_acc=0.7)\n",
    "# (910mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(5, target_p50_loss=0.2, target_seq_acc=0.7)\n",
    "# (190mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(5, target_p50_loss=0.2, target_seq_acc=0.8)\n",
    "# (472mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(8, target_p50_loss=1.0, target_seq_acc=0.8)\n",
    "# (760mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(5, target_p50_loss=1.0, target_seq_acc=0.8)\n",
    "# (471mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(5, target_p50_loss=1.0, target_seq_acc=0.75)\n",
    "# (473mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(5, target_p50_loss=1.0, target_seq_acc=0.75)\n",
    "# (380mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(5, target_p50_loss=1.0, target_seq_acc=0.80)\n",
    "# (491mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(6, target_p50_loss=1.0, target_seq_acc=0.80)\n",
    "# (380mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 8190 # *14 close to 8192\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"grammar\": 0.9})\n",
    "trainFor(160-start_epoch, target_p50_loss=1.0, target_seq_acc=0.90)\n",
    "# (190mins)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
