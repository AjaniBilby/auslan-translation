{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded epoch_110\n"
     ]
    }
   ],
   "source": [
    "# Init/Load model\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "# Define a directory to save the models\n",
    "SAVE_DIR = '../saved_models'\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "start_epoch = 110\n",
    "\n",
    "class SimpleBART(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleBART, self).__init__()\n",
    "        if start_epoch > 0:\n",
    "            self.bart = BartForConditionalGeneration.from_pretrained(os.path.join(SAVE_DIR, f'epoch_{start_epoch}'))\n",
    "            print(f'Loaded epoch_{start_epoch}')\n",
    "        else:\n",
    "            self.bart = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "            print('Loaded facebook/bart-base')\n",
    "        self.tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.bart(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "\n",
    "model = SimpleBART().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Raw Datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import csv\n",
    "\n",
    "ACCUMULATION_STEPS = 14\n",
    "BATCH_SIZE = 14 # best performing batch size so far (in execution performance)\n",
    "DATA_SIZE = 0\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=200):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        self.start_token_id = tokenizer.cls_token_id\n",
    "        self.end_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text, tokens = self.data[idx]\n",
    "        \n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=self.max_length)\n",
    "        \n",
    "        # Add start and end tokens and then pad\n",
    "        tokens = [self.start_token_id] + tokens + [self.end_token_id]\n",
    "        tokens_padded = [self.pad_token_id] * self.max_length\n",
    "        tokens_padded[:len(tokens)] = tokens\n",
    "        tokens_padded[len(tokens):] = [self.pad_token_id] * (self.max_length - len(tokens))\n",
    "        \n",
    "        return inputs[\"input_ids\"].squeeze(0), inputs[\"attention_mask\"].squeeze(0), torch.tensor(tokens_padded, dtype=torch.long)\n",
    "\n",
    "\n",
    "def load_data_from_csv(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        data = [(row[0], [int(tok) for tok in row[1].split(\",\")]) for row in reader]\n",
    "\n",
    "    return data\n",
    "\n",
    "def apply_concept(params, validation=False):\n",
    "    global validationLoader\n",
    "    global dataloader\n",
    "    global DATA_SIZE\n",
    "\n",
    "    merged_data = load_data_from_csv(f\"concept/egg.csv\")\n",
    "    \n",
    "    print(\"Concepts loaded;\")\n",
    "    for file_name, percentage in params.items():\n",
    "        data = load_data_from_csv(f\"concept/{file_name}.csv\")\n",
    "        cutoff = int(len(data) * percentage)\n",
    "        \n",
    "        if validation:\n",
    "            loaded_data = data[-cutoff:]\n",
    "        else:\n",
    "            loaded_data = data[:cutoff]\n",
    "\n",
    "        print(f\"    - {file_name}: {len(loaded_data)}\")\n",
    "        merged_data.extend(loaded_data)\n",
    "\n",
    "    DATA_SIZE = len(merged_data)\n",
    "    dataset = CustomDataset(merged_data, model.tokenizer)\n",
    "    if validation:\n",
    "        validationLoader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    else:\n",
    "        dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    print(f'  Total: {DATA_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup trainer\n",
    "import numpy as np\n",
    "\n",
    "def trainFor(num_epochs, log_freq, target_loss=0, target_acc=1.0):\n",
    "    global start_epoch\n",
    "\n",
    "    EOS_TOKEN_ID = model.tokenizer.eos_token_id\n",
    "    acc_batch = int(ACCUMULATION_STEPS / BATCH_SIZE)\n",
    "\n",
    "    for epoch in range(start_epoch+1, start_epoch+num_epochs+1):\n",
    "        start_epoch = epoch\n",
    "        model.train()\n",
    "\n",
    "        # Resetting the accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        target_met = False\n",
    "\n",
    "        # Initialize counters for accuracy calculation\n",
    "        total_correct_sequences = 0\n",
    "        total_sequences = 0\n",
    "        cumulative_loss = 0.0\n",
    "\n",
    "        # Initialize list to store batch losses\n",
    "        batch_losses = []\n",
    "\n",
    "        for batch_idx, (input_ids, attention_mask, targets) in enumerate(dataloader):\n",
    "\n",
    "            input_ids, attention_mask, targets = input_ids.to(device), attention_mask.to(device), targets.to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Identify where the EOS token is in the target sequence\n",
    "            eos_positions = (targets == EOS_TOKEN_ID).cumsum(dim=1).type(torch.bool)\n",
    "            mask = ~eos_positions | (targets == EOS_TOKEN_ID)\n",
    "\n",
    "            # Apply mask to filter out tokens after the EOS token for loss computation\n",
    "            active_loss = mask.view(-1).bool()\n",
    "            active_logits = logits.view(-1, logits.size(-1))[active_loss]\n",
    "            active_labels = targets.view(-1)[active_loss]\n",
    "            loss = criterion(active_logits, active_labels)\n",
    "\n",
    "            _, predicted = logits.max(2)\n",
    "            correct_sequences = ((predicted == targets) | ~mask).all(dim=1).float().sum().item()\n",
    "            total_sequences += targets.size(0)\n",
    "            total_correct_sequences += correct_sequences\n",
    "\n",
    "            # Accumulate the gradients\n",
    "            loss.backward()\n",
    "            loss_val = loss.item()\n",
    "\n",
    "            cumulative_loss += loss_val\n",
    "            batch_losses.append(loss_val)\n",
    "\n",
    "            isLast = batch_idx == len(dataloader) - 1\n",
    "\n",
    "            if isLast or batch_idx % log_freq == 0:\n",
    "                print(f\"Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss_val}\")\n",
    "\n",
    "            # Only perform an optimization step every ACCUMULATION_STEPS\n",
    "            if isLast or batch_idx % acc_batch == 0:\n",
    "                if loss_val <= target_loss:\n",
    "                    target_met = True\n",
    "\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        # Compute and print the accuracy for the entire epoch\n",
    "        epoch_accuracy = total_correct_sequences / total_sequences\n",
    "        cumulative_loss = cumulative_loss / len(batch_losses)\n",
    "        p25_loss = np.percentile(batch_losses, 25)\n",
    "        p50_loss = np.percentile(batch_losses, 50)\n",
    "        p75_loss = np.percentile(batch_losses, 75)\n",
    "        print(f\"Epoch: {epoch}, Accuracy: {epoch_accuracy*100:.2f}%\\n  Loss: 25%: {p25_loss:.6f} 50%: {p50_loss:.6f} 75%: {p75_loss:.6f}\\n   Avg: {cumulative_loss:.6f}\")\n",
    "\n",
    "        validate()\n",
    "\n",
    "        if epoch % 10 == 0: # Save the model\n",
    "            save_model()\n",
    "\n",
    "        if epoch_accuracy >= target_acc:\n",
    "            break\n",
    "\n",
    "        if target_met:\n",
    "            break\n",
    "\n",
    "    # Make sure last epoch is always saved\n",
    "    save_model()\n",
    "\n",
    "def save_model():\n",
    "    global start_epoch\n",
    "    model_save_path = os.path.join(SAVE_DIR, f'epoch_{start_epoch}')\n",
    "    model.bart.save_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Validator\n",
    "def validate():\n",
    "    EOS_TOKEN_ID = model.tokenizer.eos_token_id\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize counters for accuracy calculation\n",
    "    total_correct_sequences = 0\n",
    "    total_sequences = 0\n",
    "\n",
    "    # Initialize counters for average sequence accuracy within the mask\n",
    "    total_accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input_ids, attention_mask, targets) in enumerate(validationLoader):\n",
    "            input_ids, attention_mask, targets = input_ids.to(device), attention_mask.to(device), targets.to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Identify where the EOS token is in the target sequence\n",
    "            eos_positions = (targets == EOS_TOKEN_ID).cumsum(dim=1).type(torch.bool)\n",
    "            mask = ~eos_positions | (targets == EOS_TOKEN_ID)\n",
    "\n",
    "            _, predicted = logits.max(2)\n",
    "            correct_sequences = ((predicted == targets) | ~mask).all(dim=1).float().sum().item()\n",
    "            total_sequences += targets.size(0)\n",
    "            total_correct_sequences += correct_sequences\n",
    "\n",
    "            # Compute the accuracy for each sequence\n",
    "            correct_tokens_per_sequence = ((predicted == targets) & mask).float().sum(dim=1)\n",
    "            total_tokens_per_sequence = mask.float().sum(dim=1)\n",
    "            total_accuracy += (correct_tokens_per_sequence / total_tokens_per_sequence).sum().item()\n",
    "\n",
    "    # Compute and print the accuracy for the entire validation dataset\n",
    "    validation_accuracy = total_correct_sequences / total_sequences\n",
    "    print(f\"Total Seq Accuracy: {validation_accuracy*100:.3f}%\")\n",
    "    avg_accuracy = total_accuracy / total_sequences\n",
    "    print(f\"Average Sequence: {avg_accuracy*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 390\n",
      "  Total: 7199\n",
      "Epoch: 1, Batch: 0, Loss: 7.29101037979126\n",
      "Epoch: 1, Batch: 514, Loss: 2.501331090927124\n",
      "Epoch: 1, Accuracy: 0.06%\n",
      "Epoch: 2, Batch: 0, Loss: 2.7425403594970703\n",
      "Epoch: 2, Batch: 514, Loss: 2.56217098236084\n",
      "Epoch: 2, Accuracy: 0.08%\n",
      "Epoch: 3, Batch: 0, Loss: 2.961082696914673\n",
      "Epoch: 3, Batch: 514, Loss: 2.5872976779937744\n",
      "Epoch: 3, Accuracy: 0.08%\n",
      "Epoch: 4, Batch: 0, Loss: 3.54451584815979\n",
      "Epoch: 4, Batch: 514, Loss: 2.6127095222473145\n",
      "Epoch: 4, Accuracy: 0.10%\n",
      "Epoch: 5, Batch: 0, Loss: 3.0492312908172607\n",
      "Epoch: 5, Batch: 514, Loss: 2.625404119491577\n",
      "Epoch: 5, Accuracy: 0.10%\n",
      "Epoch: 6, Batch: 0, Loss: 3.1311771869659424\n",
      "Epoch: 6, Batch: 514, Loss: 2.4623067378997803\n",
      "Epoch: 6, Accuracy: 0.19%\n",
      "Epoch: 7, Batch: 0, Loss: 2.6145153045654297\n",
      "Epoch: 7, Batch: 514, Loss: 2.3633921146392822\n",
      "Epoch: 7, Accuracy: 0.22%\n",
      "Epoch: 8, Batch: 0, Loss: 3.5724732875823975\n",
      "Epoch: 8, Batch: 514, Loss: 2.420199394226074\n",
      "Epoch: 8, Accuracy: 0.57%\n",
      "Epoch: 9, Batch: 0, Loss: 4.175498008728027\n",
      "Epoch: 9, Batch: 514, Loss: 2.2631406784057617\n",
      "Epoch: 9, Accuracy: 2.10%\n",
      "Epoch: 10, Batch: 0, Loss: 2.1199870109558105\n",
      "Epoch: 10, Batch: 514, Loss: 2.4418230056762695\n",
      "Epoch: 10, Accuracy: 5.24%\n",
      "Epoch: 11, Batch: 0, Loss: 2.5211238861083984\n",
      "Epoch: 11, Batch: 514, Loss: 1.7909355163574219\n",
      "Epoch: 11, Accuracy: 9.86%\n",
      "Epoch: 12, Batch: 0, Loss: 2.5018563270568848\n",
      "Epoch: 12, Batch: 514, Loss: 3.5700972080230713\n",
      "Epoch: 12, Accuracy: 14.79%\n",
      "Epoch: 13, Batch: 0, Loss: 1.2482454776763916\n",
      "Epoch: 13, Batch: 514, Loss: 2.031683921813965\n",
      "Epoch: 13, Accuracy: 18.57%\n",
      "Epoch: 14, Batch: 0, Loss: 2.676171064376831\n",
      "Epoch: 14, Batch: 514, Loss: 1.9091053009033203\n",
      "Epoch: 14, Accuracy: 23.11%\n",
      "Epoch: 15, Batch: 0, Loss: 1.3341926336288452\n",
      "Epoch: 15, Batch: 514, Loss: 1.5460504293441772\n",
      "Epoch: 15, Accuracy: 27.81%\n",
      "Epoch: 16, Batch: 0, Loss: 1.1929370164871216\n",
      "Epoch: 16, Batch: 514, Loss: 1.622398018836975\n",
      "Epoch: 16, Accuracy: 31.12%\n",
      "Epoch: 17, Batch: 0, Loss: 1.173069953918457\n",
      "Epoch: 17, Batch: 514, Loss: 1.5345700979232788\n",
      "Epoch: 17, Accuracy: 34.50%\n",
      "Epoch: 18, Batch: 0, Loss: 1.2522201538085938\n",
      "Epoch: 18, Batch: 514, Loss: 2.886545419692993\n",
      "Epoch: 18, Accuracy: 37.56%\n",
      "Epoch: 19, Batch: 0, Loss: 1.1483633518218994\n",
      "Epoch: 19, Batch: 514, Loss: 1.4035922288894653\n",
      "Epoch: 19, Accuracy: 40.19%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = BATCH_SIZE # pure memorisation so accumulation won't help\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.01})\n",
    "trainFor(50, log_freq=DATA_SIZE, target_acc=0.40)\n",
    "# (31mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 3902\n",
      "  Total: 10711\n",
      "Epoch: 20, Batch: 0, Loss: 5.020002841949463\n",
      "Epoch: 20, Batch: 765, Loss: 0.16530807316303253\n",
      "Epoch: 20, Accuracy: 29.16%\n",
      "Epoch: 21, Batch: 0, Loss: 2.432830572128296\n",
      "Epoch: 21, Batch: 765, Loss: 4.899008274078369\n",
      "Epoch: 21, Accuracy: 31.86%\n",
      "Epoch: 22, Batch: 0, Loss: 2.754391670227051\n",
      "Epoch: 22, Batch: 765, Loss: 0.5231565237045288\n",
      "Epoch: 22, Accuracy: 35.51%\n",
      "Epoch: 23, Batch: 0, Loss: 1.9788975715637207\n",
      "Epoch: 23, Batch: 765, Loss: 0.11301183700561523\n",
      "Epoch: 23, Accuracy: 38.34%\n",
      "Epoch: 24, Batch: 0, Loss: 1.2154724597930908\n",
      "Epoch: 24, Batch: 765, Loss: 0.007895281538367271\n",
      "Epoch: 24, Accuracy: 40.39%\n",
      "Epoch: 25, Batch: 0, Loss: 1.191716194152832\n",
      "Epoch: 25, Batch: 765, Loss: 0.015043791383504868\n",
      "Epoch: 25, Accuracy: 42.92%\n",
      "Epoch: 26, Batch: 0, Loss: 1.854417324066162\n",
      "Epoch: 26, Batch: 765, Loss: 1.0427758693695068\n",
      "Epoch: 26, Accuracy: 44.90%\n",
      "Epoch: 27, Batch: 0, Loss: 1.3035759925842285\n",
      "Epoch: 27, Batch: 765, Loss: 0.004182247910648584\n",
      "Epoch: 27, Accuracy: 47.53%\n",
      "Epoch: 28, Batch: 0, Loss: 1.544390320777893\n",
      "Epoch: 28, Batch: 765, Loss: 0.986763060092926\n",
      "Epoch: 28, Accuracy: 49.64%\n",
      "Epoch: 29, Batch: 0, Loss: 0.5848762392997742\n",
      "Epoch: 29, Batch: 765, Loss: 1.3285237550735474\n",
      "Epoch: 29, Accuracy: 51.00%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = BATCH_SIZE # pure memorisation so accumulation won't help\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.10})\n",
    "trainFor(50, log_freq=DATA_SIZE, target_acc=0.50)\n",
    "# (24mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 7805\n",
      "  Total: 14614\n",
      "Epoch: 30, Batch: 0, Loss: 1.6802232265472412\n",
      "Epoch: 30, Batch: 1043, Loss: 1.063194990158081\n",
      "Epoch: 30, Accuracy: 41.64%\n",
      "Epoch: 31, Batch: 0, Loss: 0.6703682541847229\n",
      "Epoch: 31, Batch: 1043, Loss: 0.3829524517059326\n",
      "Epoch: 31, Accuracy: 44.61%\n",
      "Epoch: 32, Batch: 0, Loss: 0.38985922932624817\n",
      "Epoch: 32, Batch: 1043, Loss: 0.33271169662475586\n",
      "Epoch: 32, Accuracy: 46.08%\n",
      "Epoch: 33, Batch: 0, Loss: 0.4413485825061798\n",
      "Epoch: 33, Batch: 1043, Loss: 0.2826402485370636\n",
      "Epoch: 33, Accuracy: 46.93%\n",
      "Epoch: 34, Batch: 0, Loss: 0.39702412486076355\n",
      "Epoch: 34, Batch: 1043, Loss: 0.5775324106216431\n",
      "Epoch: 34, Accuracy: 48.26%\n",
      "Epoch: 35, Batch: 0, Loss: 0.5960874557495117\n",
      "Epoch: 35, Batch: 1043, Loss: 0.6266477108001709\n",
      "Epoch: 35, Accuracy: 50.28%\n",
      "Epoch: 36, Batch: 0, Loss: 0.5490836501121521\n",
      "Epoch: 36, Batch: 1043, Loss: 0.8670615553855896\n",
      "Epoch: 36, Accuracy: 50.96%\n",
      "Epoch: 37, Batch: 0, Loss: 0.3249604403972626\n",
      "Epoch: 37, Batch: 1043, Loss: 0.7273703813552856\n",
      "Epoch: 37, Accuracy: 51.57%\n",
      "Epoch: 38, Batch: 0, Loss: 0.46123382449150085\n",
      "Epoch: 38, Batch: 1043, Loss: 0.3521355390548706\n",
      "Epoch: 38, Accuracy: 53.06%\n",
      "Epoch: 39, Batch: 0, Loss: 0.3375380039215088\n",
      "Epoch: 39, Batch: 1043, Loss: 0.46154654026031494\n",
      "Epoch: 39, Accuracy: 53.76%\n",
      "Epoch: 40, Batch: 0, Loss: 0.36984050273895264\n",
      "Epoch: 40, Batch: 1043, Loss: 0.21578435599803925\n",
      "Epoch: 40, Accuracy: 54.33%\n",
      "Epoch: 41, Batch: 0, Loss: 0.3986719846725464\n",
      "Epoch: 41, Batch: 1043, Loss: 0.1839827299118042\n",
      "Epoch: 41, Accuracy: 55.10%\n",
      "Epoch: 42, Batch: 0, Loss: 0.21343669295310974\n",
      "Epoch: 42, Batch: 1043, Loss: 0.5373435020446777\n",
      "Epoch: 42, Accuracy: 56.10%\n",
      "Epoch: 43, Batch: 0, Loss: 0.30255600810050964\n",
      "Epoch: 43, Batch: 1043, Loss: 0.29068267345428467\n",
      "Epoch: 43, Accuracy: 57.13%\n",
      "Epoch: 44, Batch: 0, Loss: 0.22619812190532684\n",
      "Epoch: 44, Batch: 1043, Loss: 0.30810096859931946\n",
      "Epoch: 44, Accuracy: 56.96%\n",
      "Epoch: 45, Batch: 0, Loss: 0.23488475382328033\n",
      "Epoch: 45, Batch: 1043, Loss: 0.5573174953460693\n",
      "Epoch: 45, Accuracy: 57.59%\n",
      "Epoch: 46, Batch: 0, Loss: 0.17645005881786346\n",
      "Epoch: 46, Batch: 1043, Loss: 0.27472856640815735\n",
      "Epoch: 46, Accuracy: 58.45%\n",
      "Epoch: 47, Batch: 0, Loss: 0.2245737463235855\n",
      "Epoch: 47, Batch: 1043, Loss: 0.3146197199821472\n",
      "Epoch: 47, Accuracy: 59.98%\n",
      "Epoch: 48, Batch: 0, Loss: 0.23582205176353455\n",
      "Epoch: 48, Batch: 1043, Loss: 0.2823364734649658\n",
      "Epoch: 48, Accuracy: 59.26%\n",
      "Epoch: 49, Batch: 0, Loss: 0.40344715118408203\n",
      "Epoch: 49, Batch: 1043, Loss: 0.22748519480228424\n",
      "Epoch: 49, Accuracy: 60.85%\n",
      "Epoch: 50, Batch: 0, Loss: 0.1758679449558258\n",
      "Epoch: 50, Batch: 1043, Loss: 0.19268345832824707\n",
      "Epoch: 50, Accuracy: 61.35%\n",
      "Epoch: 51, Batch: 0, Loss: 0.16084297001361847\n",
      "Epoch: 51, Batch: 1043, Loss: 0.13087250292301178\n",
      "Epoch: 51, Accuracy: 61.84%\n",
      "Epoch: 52, Batch: 0, Loss: 0.15427036583423615\n",
      "Epoch: 52, Batch: 1043, Loss: 0.26514002680778503\n",
      "Epoch: 52, Accuracy: 62.36%\n",
      "Epoch: 53, Batch: 0, Loss: 0.24628597497940063\n",
      "Epoch: 53, Batch: 1043, Loss: 0.31328442692756653\n",
      "Epoch: 53, Accuracy: 63.43%\n",
      "Epoch: 54, Batch: 0, Loss: 0.2258092761039734\n",
      "Epoch: 54, Batch: 1043, Loss: 0.3287239074707031\n",
      "Epoch: 54, Accuracy: 63.26%\n",
      "Epoch: 55, Batch: 0, Loss: 0.26508310437202454\n",
      "Epoch: 55, Batch: 1043, Loss: 0.14774440228939056\n",
      "Epoch: 55, Accuracy: 64.22%\n",
      "Epoch: 56, Batch: 0, Loss: 0.1625947505235672\n",
      "Epoch: 56, Batch: 1043, Loss: 0.14354142546653748\n",
      "Epoch: 56, Accuracy: 65.51%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 28 # *14 close to 32\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.20})\n",
    "trainFor(50, log_freq=DATA_SIZE, target_acc=0.65)\n",
    "# (81mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aiming for:\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\frac{unique}{tokens} &= \\frac{4174}{6808} = 61.31\\%  & \\text{sign pairs to unique text} \\\\\n",
    "  \\frac{text}{tokens}   &= \\frac{5342}{6808}  = 78.47\\% & \\text{sign pairs to text} \\\\\n",
    "  & & \\text{unique meaning the text is only used for one tokenID}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "i.e. there are six different signs which can be used for \"present\"  \n",
    "which means we're actually aiming for $96\\%$ effective accuracy $\\frac{75\\%}{78\\%}$\n",
    "\n",
    "But we don't want to over-fit either  \n",
    "Hence why we slowly introduce new concepts while still memorising vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 35124\n",
      "  Total: 41933\n",
      "Epoch: 57, Batch: 0, Loss: 0.31596410274505615\n",
      "Epoch: 57, Batch: 2995, Loss: 0.9586284160614014\n",
      "Epoch: 57, Accuracy: 41.30%\n",
      "Epoch: 58, Batch: 0, Loss: 0.23302768170833588\n",
      "Epoch: 58, Batch: 2995, Loss: 2.3223114013671875\n",
      "Epoch: 58, Accuracy: 42.93%\n",
      "Epoch: 59, Batch: 0, Loss: 0.3411206305027008\n",
      "Epoch: 59, Batch: 2995, Loss: 0.14493200182914734\n",
      "Epoch: 59, Accuracy: 44.05%\n",
      "Epoch: 60, Batch: 0, Loss: 0.1739943027496338\n",
      "Epoch: 60, Batch: 2995, Loss: 0.24309362471103668\n",
      "Epoch: 60, Accuracy: 44.64%\n",
      "Epoch: 61, Batch: 0, Loss: 0.4015417993068695\n",
      "Epoch: 61, Batch: 2995, Loss: 0.5365091562271118\n",
      "Epoch: 61, Accuracy: 45.30%\n",
      "Epoch: 62, Batch: 0, Loss: 0.30252334475517273\n",
      "Epoch: 62, Batch: 2995, Loss: 0.00811807345598936\n",
      "Epoch: 62, Accuracy: 45.38%\n",
      "Epoch: 63, Batch: 0, Loss: 0.2994730770587921\n",
      "Epoch: 63, Batch: 2995, Loss: 0.10692374408245087\n",
      "Epoch: 63, Accuracy: 46.49%\n",
      "Epoch: 64, Batch: 0, Loss: 0.22777970135211945\n",
      "Epoch: 64, Batch: 2995, Loss: 0.1944780945777893\n",
      "Epoch: 64, Accuracy: 46.68%\n",
      "Epoch: 65, Batch: 0, Loss: 0.3099944293498993\n",
      "Epoch: 65, Batch: 2995, Loss: 0.2250659316778183\n",
      "Epoch: 65, Accuracy: 46.91%\n",
      "Epoch: 66, Batch: 0, Loss: 0.26913025975227356\n",
      "Epoch: 66, Batch: 2995, Loss: 0.17705270648002625\n",
      "Epoch: 66, Accuracy: 47.51%\n",
      "Epoch: 67, Batch: 0, Loss: 0.39672741293907166\n",
      "Epoch: 67, Batch: 2995, Loss: 0.1292150318622589\n",
      "Epoch: 67, Accuracy: 47.38%\n",
      "Epoch: 68, Batch: 0, Loss: 0.2636815011501312\n",
      "Epoch: 68, Batch: 2995, Loss: 0.1743547022342682\n",
      "Epoch: 68, Accuracy: 48.25%\n",
      "Epoch: 69, Batch: 0, Loss: 0.2748456299304962\n",
      "Epoch: 69, Batch: 2995, Loss: 0.06683206558227539\n",
      "Epoch: 69, Accuracy: 48.51%\n",
      "Epoch: 70, Batch: 0, Loss: 0.19758014380931854\n",
      "Epoch: 70, Batch: 2995, Loss: 0.39083489775657654\n",
      "Epoch: 70, Accuracy: 48.56%\n",
      "Epoch: 71, Batch: 0, Loss: 0.23591352999210358\n",
      "Epoch: 71, Batch: 2995, Loss: 0.33517664670944214\n",
      "Epoch: 71, Accuracy: 49.26%\n",
      "Epoch: 72, Batch: 0, Loss: 0.17347930371761322\n",
      "Epoch: 72, Batch: 2995, Loss: 0.07138797640800476\n",
      "Epoch: 72, Accuracy: 49.49%\n",
      "Epoch: 73, Batch: 0, Loss: 0.1451151967048645\n",
      "Epoch: 73, Batch: 2995, Loss: 0.12522180378437042\n",
      "Epoch: 73, Accuracy: 50.19%\n",
      "Epoch: 74, Batch: 0, Loss: 0.26464205980300903\n",
      "Epoch: 74, Batch: 2995, Loss: 0.06910330802202225\n",
      "Epoch: 74, Accuracy: 50.55%\n",
      "Epoch: 75, Batch: 0, Loss: 0.24648334085941315\n",
      "Epoch: 75, Batch: 2995, Loss: 0.17002207040786743\n",
      "Epoch: 75, Accuracy: 50.99%\n",
      "Epoch: 76, Batch: 0, Loss: 0.2320428192615509\n",
      "Epoch: 76, Batch: 2995, Loss: 0.09815863519906998\n",
      "Epoch: 76, Accuracy: 51.30%\n",
      "Epoch: 77, Batch: 0, Loss: 0.19269657135009766\n",
      "Epoch: 77, Batch: 2995, Loss: 0.09969694912433624\n",
      "Epoch: 77, Accuracy: 51.97%\n",
      "Epoch: 78, Batch: 0, Loss: 0.16590124368667603\n",
      "Epoch: 78, Batch: 2995, Loss: 0.15912874042987823\n",
      "Epoch: 78, Accuracy: 52.57%\n",
      "Epoch: 79, Batch: 0, Loss: 0.16050593554973602\n",
      "Epoch: 79, Batch: 2995, Loss: 0.12817367911338806\n",
      "Epoch: 79, Accuracy: 52.77%\n",
      "Epoch: 80, Batch: 0, Loss: 0.27854102849960327\n",
      "Epoch: 80, Batch: 2995, Loss: 0.4488683342933655\n",
      "Epoch: 80, Accuracy: 53.66%\n",
      "Epoch: 81, Batch: 0, Loss: 0.19618991017341614\n",
      "Epoch: 81, Batch: 2995, Loss: 0.2774103581905365\n",
      "Epoch: 81, Accuracy: 53.75%\n",
      "Epoch: 82, Batch: 0, Loss: 0.19030262529850006\n",
      "Epoch: 82, Batch: 2995, Loss: 0.06313173472881317\n",
      "Epoch: 82, Accuracy: 54.35%\n",
      "Epoch: 83, Batch: 0, Loss: 0.17654556035995483\n",
      "Epoch: 83, Batch: 2995, Loss: 0.10920172184705734\n",
      "Epoch: 83, Accuracy: 55.38%\n",
      "Epoch: 84, Batch: 0, Loss: 0.21183012425899506\n",
      "Epoch: 84, Batch: 2995, Loss: 0.13914400339126587\n",
      "Epoch: 84, Accuracy: 55.97%\n",
      "Epoch: 85, Batch: 0, Loss: 0.0949510782957077\n",
      "Epoch: 85, Batch: 2995, Loss: 0.09769195318222046\n",
      "Epoch: 85, Accuracy: 56.08%\n",
      "Epoch: 86, Batch: 0, Loss: 0.1923302859067917\n",
      "Epoch: 86, Batch: 2995, Loss: 0.09219955652952194\n",
      "Epoch: 86, Accuracy: 57.20%\n",
      "Epoch: 87, Batch: 0, Loss: 0.11855534464120865\n",
      "Epoch: 87, Batch: 2995, Loss: 0.2677000164985657\n",
      "Epoch: 87, Accuracy: 57.35%\n",
      "Epoch: 88, Batch: 0, Loss: 0.2690873146057129\n",
      "Epoch: 88, Batch: 2995, Loss: 0.06679622828960419\n",
      "Epoch: 88, Accuracy: 58.68%\n",
      "Epoch: 89, Batch: 0, Loss: 0.15962879359722137\n",
      "Epoch: 89, Batch: 2995, Loss: 0.0481516532599926\n",
      "Epoch: 89, Accuracy: 59.47%\n",
      "Epoch: 90, Batch: 0, Loss: 0.16051457822322845\n",
      "Epoch: 90, Batch: 2995, Loss: 0.25439906120300293\n",
      "Epoch: 90, Accuracy: 59.88%\n",
      "Epoch: 91, Batch: 0, Loss: 0.1684536635875702\n",
      "Epoch: 91, Batch: 2995, Loss: 0.054328083992004395\n",
      "Epoch: 91, Accuracy: 60.38%\n",
      "Epoch: 92, Batch: 0, Loss: 0.16755083203315735\n",
      "Epoch: 92, Batch: 2995, Loss: 0.0005131198558956385\n",
      "Epoch: 92, Accuracy: 61.69%\n",
      "Epoch: 93, Batch: 0, Loss: 0.09251119196414948\n",
      "Epoch: 93, Batch: 2995, Loss: 0.3965717852115631\n",
      "Epoch: 93, Accuracy: 62.09%\n",
      "Epoch: 94, Batch: 0, Loss: 0.15214356780052185\n",
      "Epoch: 94, Batch: 2995, Loss: 0.1574518233537674\n",
      "Epoch: 94, Accuracy: 62.91%\n",
      "Epoch: 95, Batch: 0, Loss: 0.16833633184432983\n",
      "Epoch: 95, Batch: 2995, Loss: 0.004375031217932701\n",
      "Epoch: 95, Accuracy: 63.49%\n",
      "Epoch: 96, Batch: 0, Loss: 0.19574853777885437\n",
      "Epoch: 96, Batch: 2995, Loss: 0.10663160681724548\n",
      "Epoch: 96, Accuracy: 64.47%\n",
      "Epoch: 97, Batch: 0, Loss: 0.09820951521396637\n",
      "Epoch: 97, Batch: 2995, Loss: 0.03886346518993378\n",
      "Epoch: 97, Accuracy: 65.44%\n",
      "Epoch: 98, Batch: 0, Loss: 0.04456949606537819\n",
      "Epoch: 98, Batch: 2995, Loss: 0.2829127609729767\n",
      "Epoch: 98, Accuracy: 66.42%\n",
      "Epoch: 99, Batch: 0, Loss: 0.13545942306518555\n",
      "Epoch: 99, Batch: 2995, Loss: 0.03430270776152611\n",
      "Epoch: 99, Accuracy: 67.10%\n",
      "Epoch: 100, Batch: 0, Loss: 0.053783852607011795\n",
      "Epoch: 100, Batch: 2995, Loss: 0.0007143553229980171\n",
      "Epoch: 100, Accuracy: 67.77%\n",
      "Epoch: 101, Batch: 0, Loss: 0.16276930272579193\n",
      "Epoch: 101, Batch: 2995, Loss: 0.04191448539495468\n",
      "Epoch: 101, Accuracy: 68.76%\n",
      "Epoch: 102, Batch: 0, Loss: 0.12825918197631836\n",
      "Epoch: 102, Batch: 2995, Loss: 0.10072652250528336\n",
      "Epoch: 102, Accuracy: 69.65%\n",
      "Epoch: 103, Batch: 0, Loss: 0.07602100819349289\n",
      "Epoch: 103, Batch: 2995, Loss: 0.06044470891356468\n",
      "Epoch: 103, Accuracy: 70.21%\n",
      "Epoch: 104, Batch: 0, Loss: 0.08273453265428543\n",
      "Epoch: 104, Batch: 2995, Loss: 0.11134433001279831\n",
      "Epoch: 104, Accuracy: 70.91%\n",
      "Epoch: 105, Batch: 0, Loss: 0.1069428101181984\n",
      "Epoch: 105, Batch: 2995, Loss: 0.07061998546123505\n",
      "Epoch: 105, Accuracy: 71.68%\n",
      "Epoch: 106, Batch: 0, Loss: 0.11069516092538834\n",
      "Epoch: 106, Batch: 2995, Loss: 0.10707979649305344\n",
      "Epoch: 106, Accuracy: 72.65%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 70 # *14 close to 64\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.9})\n",
    "trainFor(50, log_freq=DATA_SIZE, target_acc=0.75)\n",
    "# (416mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 3902\n",
      "  Total: 10711\n",
      "Validation Accuracy: 65.213%\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "  Total: 6809\n",
      "Validation Accuracy: 80.320%\n",
      "Concepts loaded;\n",
      "    - noise: 3902\n",
      "  Total: 3903\n",
      "Validation Accuracy: 38.868%\n"
     ]
    }
   ],
   "source": [
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 35124\n",
      "  Total: 41933\n",
      "Epoch: 107, Batch: 0, Loss: 0.14195597171783447\n",
      "Epoch: 107, Batch: 2995, Loss: 0.0344601608812809\n",
      "Epoch: 107, Accuracy: 72.98%\n",
      "Epoch: 108, Batch: 0, Loss: 0.10983139276504517\n",
      "Epoch: 108, Batch: 2995, Loss: 0.04287264868617058\n",
      "Epoch: 108, Accuracy: 72.86%\n",
      "Epoch: 109, Batch: 0, Loss: 0.08244488388299942\n",
      "Epoch: 109, Batch: 2995, Loss: 0.07554608583450317\n",
      "Epoch: 109, Accuracy: 73.84%\n",
      "Epoch: 110, Batch: 0, Loss: 0.06210318207740784\n",
      "Epoch: 110, Batch: 2995, Loss: 0.13856537640094757\n",
      "Epoch: 110, Accuracy: 74.86%\n",
      "Epoch: 111, Batch: 0, Loss: 0.13895009458065033\n",
      "Epoch: 111, Batch: 2995, Loss: 0.005273606162518263\n",
      "Epoch: 111, Accuracy: 75.72%\n",
      "Epoch: 112, Batch: 0, Loss: 0.09678803384304047\n",
      "Epoch: 112, Batch: 2995, Loss: 0.08273360878229141\n",
      "Epoch: 112, Accuracy: 76.09%\n",
      "Epoch: 113, Batch: 0, Loss: 0.07797343283891678\n",
      "Epoch: 113, Batch: 2995, Loss: 0.04882273077964783\n",
      "Epoch: 113, Accuracy: 77.07%\n",
      "Epoch: 114, Batch: 0, Loss: 0.0355854332447052\n",
      "Epoch: 114, Batch: 2995, Loss: 0.05263584852218628\n",
      "Epoch: 114, Accuracy: 78.04%\n",
      "Epoch: 115, Batch: 0, Loss: 0.060354914516210556\n",
      "Epoch: 115, Batch: 2995, Loss: 0.0815064013004303\n",
      "Epoch: 115, Accuracy: 78.75%\n",
      "Epoch: 116, Batch: 0, Loss: 0.16046376526355743\n",
      "Epoch: 116, Batch: 2995, Loss: 0.008502037264406681\n",
      "Epoch: 116, Accuracy: 79.64%\n",
      "Epoch: 117, Batch: 0, Loss: 0.06979823857545853\n",
      "Epoch: 117, Batch: 2995, Loss: 0.022409379482269287\n",
      "Epoch: 117, Accuracy: 80.65%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 28 # *14 close to 32\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.9})\n",
    "trainFor(50, log_freq=DATA_SIZE, target_acc=0.8)\n",
    "# (94mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 3902\n",
      "  Total: 10711\n",
      "Validation Accuracy: 65.139%\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "  Total: 6809\n",
      "Validation Accuracy: 80.291%\n",
      "Concepts loaded;\n",
      "    - noise: 3902\n",
      "  Total: 3903\n",
      "Validation Accuracy: 38.714%\n"
     ]
    }
   ],
   "source": [
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 35124\n",
      "  Total: 41933\n",
      "Epoch: 118, Batch: 0, Loss: 0.019620144739747047\n",
      "Epoch: 118, Batch: 2995, Loss: 0.0025075555313378572\n",
      "Epoch: 118, Accuracy: 81.42%\n",
      "Epoch: 119, Batch: 0, Loss: 0.08252128958702087\n",
      "Epoch: 119, Batch: 2995, Loss: 0.09791643917560577\n",
      "Epoch: 119, Accuracy: 82.11%\n",
      "Epoch: 120, Batch: 0, Loss: 0.09593144059181213\n",
      "Epoch: 120, Batch: 2995, Loss: 0.24362444877624512\n",
      "Epoch: 120, Accuracy: 83.02%\n",
      "Epoch: 121, Batch: 0, Loss: 0.2580302059650421\n",
      "Epoch: 121, Batch: 2995, Loss: 0.1866842806339264\n",
      "Epoch: 121, Accuracy: 83.22%\n",
      "Epoch: 122, Batch: 0, Loss: 0.049325548112392426\n",
      "Epoch: 122, Batch: 2995, Loss: 0.00907761137932539\n",
      "Epoch: 122, Accuracy: 84.24%\n",
      "Epoch: 123, Batch: 0, Loss: 0.04175214096903801\n",
      "Epoch: 123, Batch: 2995, Loss: 0.08660128712654114\n",
      "Epoch: 123, Accuracy: 84.64%\n",
      "Epoch: 124, Batch: 0, Loss: 0.068450927734375\n",
      "Epoch: 124, Batch: 2995, Loss: 0.05998029559850693\n",
      "Epoch: 124, Accuracy: 84.78%\n",
      "Epoch: 125, Batch: 0, Loss: 0.03997909650206566\n",
      "Epoch: 125, Batch: 2995, Loss: 0.12918606400489807\n",
      "Epoch: 125, Accuracy: 85.64%\n",
      "Epoch: 126, Batch: 0, Loss: 0.027696026489138603\n",
      "Epoch: 126, Batch: 2995, Loss: 0.013295925222337246\n",
      "Epoch: 126, Accuracy: 85.85%\n",
      "Epoch: 127, Batch: 0, Loss: 0.03635474294424057\n",
      "Epoch: 127, Batch: 2995, Loss: 0.048939045518636703\n",
      "Epoch: 127, Accuracy: 86.76%\n",
      "Epoch: 128, Batch: 0, Loss: 0.09433317929506302\n",
      "Epoch: 128, Batch: 2995, Loss: 0.0058990600518882275\n",
      "Epoch: 128, Accuracy: 87.02%\n",
      "Epoch: 129, Batch: 0, Loss: 0.0524800568819046\n",
      "Epoch: 129, Batch: 2995, Loss: 0.0251808799803257\n",
      "Epoch: 129, Accuracy: 87.65%\n",
      "Epoch: 130, Batch: 0, Loss: 0.05564504861831665\n",
      "Epoch: 130, Batch: 2995, Loss: 0.026717619970440865\n",
      "Epoch: 130, Accuracy: 87.89%\n",
      "Epoch: 131, Batch: 0, Loss: 0.039152950048446655\n",
      "Epoch: 131, Batch: 2995, Loss: 0.021743280813097954\n",
      "Epoch: 131, Accuracy: 88.43%\n",
      "Epoch: 132, Batch: 0, Loss: 0.02784128673374653\n",
      "Epoch: 132, Batch: 2995, Loss: 0.0554889477789402\n",
      "Epoch: 132, Accuracy: 88.51%\n",
      "Epoch: 133, Batch: 0, Loss: 0.019094012677669525\n",
      "Epoch: 133, Batch: 2995, Loss: 0.009843218140304089\n",
      "Epoch: 133, Accuracy: 88.81%\n",
      "Epoch: 134, Batch: 0, Loss: 0.05620520934462547\n",
      "Epoch: 134, Batch: 2995, Loss: 0.01189626008272171\n",
      "Epoch: 134, Accuracy: 89.13%\n",
      "Epoch: 135, Batch: 0, Loss: 0.022824177518486977\n",
      "Epoch: 135, Batch: 2995, Loss: 0.040390197187662125\n",
      "Epoch: 135, Accuracy: 89.46%\n",
      "Epoch: 136, Batch: 0, Loss: 0.006706452462822199\n",
      "Epoch: 136, Batch: 2995, Loss: 0.16454750299453735\n",
      "Epoch: 136, Accuracy: 89.48%\n",
      "Epoch: 137, Batch: 0, Loss: 0.12312052398920059\n",
      "Epoch: 137, Batch: 2995, Loss: 0.11360158026218414\n",
      "Epoch: 137, Accuracy: 90.49%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 28 # *14 close to 32\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.9})\n",
    "trainFor(50, log_freq=DATA_SIZE, target_acc=0.9)\n",
    "# (172mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 3902\n",
      "  Total: 10711\n",
      "Validation Accuracy: 65.055%\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "  Total: 6809\n",
      "Validation Accuracy: 80.276%\n",
      "Concepts loaded;\n",
      "    - noise: 3902\n",
      "  Total: 3903\n",
      "Validation Accuracy: 38.509%\n"
     ]
    }
   ],
   "source": [
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were no meaningful validation accuracy improvements since epoch $106$, so we rewound back to that point.  \n",
    "We then regenerated the noise samples with $\\times4$ the number of samples in the set from before.\n",
    "\n",
    "This new generation of sample data may lead to a value in the new validation sample possibly have existed in the previous training set.  \n",
    "However due to the large increase in size, and the random nature of the entropic sort the influences of this are kept to a minimum.\n",
    "\n",
    "Just generating this entropic dataset took $25mins$\n",
    "\n",
    "We also altered the code so `apply_concept` saves to a different namespace for validation and training meaning both datasets can be loaded at once  \n",
    "This allows us to easily run validation after each training epoch for greater tracking of progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 35132\n",
      "  Total: 41941\n",
      "Epoch: 107, Batch: 0, Loss: 0.17003555595874786\n",
      "Epoch: 107, Batch: 2995, Loss: 0.3649917244911194\n",
      "Epoch: 107, Accuracy: 44.53%\n",
      "  Loss: 25%: 0.266961 50%: 0.322859 75%: 0.401827\n",
      "   Avg: 0.376571\n",
      "Validation Accuracy: 52.558%\n",
      "Epoch: 108, Batch: 0, Loss: 0.2767481803894043\n",
      "Epoch: 108, Batch: 2995, Loss: 0.2282908856868744\n",
      "Epoch: 108, Accuracy: 45.71%\n",
      "  Loss: 25%: 0.236131 50%: 0.285327 75%: 0.352968\n",
      "   Avg: 0.327862\n",
      "Validation Accuracy: 52.785%\n",
      "Epoch: 109, Batch: 0, Loss: 0.2816326320171356\n",
      "Epoch: 109, Batch: 2995, Loss: 0.44868266582489014\n",
      "Epoch: 109, Accuracy: 45.96%\n",
      "  Loss: 25%: 0.224561 50%: 0.274050 75%: 0.334460\n",
      "   Avg: 0.311470\n",
      "Validation Accuracy: 52.669%\n",
      "Epoch: 110, Batch: 0, Loss: 0.3383205533027649\n",
      "Epoch: 110, Batch: 2995, Loss: 0.23295405507087708\n",
      "Epoch: 110, Accuracy: 46.30%\n",
      "  Loss: 25%: 0.220841 50%: 0.266846 75%: 0.325280\n",
      "   Avg: 0.301671\n",
      "Validation Accuracy: 52.977%\n",
      "Epoch: 111, Batch: 0, Loss: 0.20712679624557495\n",
      "Epoch: 111, Batch: 2995, Loss: 0.2577035427093506\n",
      "Epoch: 111, Accuracy: 46.75%\n",
      "  Loss: 25%: 0.212789 50%: 0.257295 75%: 0.313136\n",
      "   Avg: 0.290009\n",
      "Validation Accuracy: 52.968%\n",
      "Epoch: 112, Batch: 0, Loss: 0.20916296541690826\n",
      "Epoch: 112, Batch: 2995, Loss: 0.30026355385780334\n",
      "Epoch: 112, Accuracy: 46.83%\n",
      "  Loss: 25%: 0.208642 50%: 0.254398 75%: 0.308142\n",
      "   Avg: 0.286325\n",
      "Validation Accuracy: 52.995%\n",
      "Epoch: 113, Batch: 0, Loss: 0.2102300375699997\n",
      "Epoch: 113, Batch: 2995, Loss: 0.2339402735233307\n",
      "Epoch: 113, Accuracy: 47.06%\n",
      "  Loss: 25%: 0.203844 50%: 0.250503 75%: 0.302489\n",
      "   Avg: 0.278928\n",
      "Validation Accuracy: 53.044%\n",
      "Epoch: 114, Batch: 0, Loss: 0.13348814845085144\n",
      "Epoch: 114, Batch: 2995, Loss: 0.3739162087440491\n",
      "Epoch: 114, Accuracy: 47.30%\n",
      "  Loss: 25%: 0.204021 50%: 0.247338 75%: 0.298625\n",
      "   Avg: 0.275814\n",
      "Validation Accuracy: 52.968%\n",
      "Epoch: 115, Batch: 0, Loss: 0.42626771330833435\n",
      "Epoch: 115, Batch: 2995, Loss: 0.2663637697696686\n",
      "Epoch: 115, Accuracy: 47.35%\n",
      "  Loss: 25%: 0.201425 50%: 0.244408 75%: 0.296816\n",
      "   Avg: 0.273569\n",
      "Validation Accuracy: 52.865%\n",
      "Epoch: 116, Batch: 0, Loss: 0.1900201290845871\n",
      "Epoch: 116, Batch: 2995, Loss: 0.26499834656715393\n",
      "Epoch: 116, Accuracy: 47.44%\n",
      "  Loss: 25%: 0.200511 50%: 0.240795 75%: 0.290888\n",
      "   Avg: 0.268129\n",
      "Validation Accuracy: 53.062%\n",
      "Epoch: 117, Batch: 0, Loss: 0.22307926416397095\n",
      "Epoch: 117, Batch: 2995, Loss: 0.20544631779193878\n",
      "Epoch: 117, Accuracy: 47.48%\n",
      "  Loss: 25%: 0.198876 50%: 0.238265 75%: 0.288914\n",
      "   Avg: 0.264223\n",
      "Validation Accuracy: 52.968%\n",
      "Epoch: 118, Batch: 0, Loss: 0.4125089943408966\n",
      "Epoch: 118, Batch: 2995, Loss: 0.33250147104263306\n",
      "Epoch: 118, Accuracy: 47.98%\n",
      "  Loss: 25%: 0.195021 50%: 0.236211 75%: 0.286903\n",
      "   Avg: 0.260728\n",
      "Validation Accuracy: 53.106%\n",
      "Epoch: 119, Batch: 0, Loss: 0.11782599240541458\n",
      "Epoch: 119, Batch: 2995, Loss: 0.6778988838195801\n",
      "Epoch: 119, Accuracy: 47.78%\n",
      "  Loss: 25%: 0.194708 50%: 0.235795 75%: 0.282192\n",
      "   Avg: 0.257044\n",
      "Validation Accuracy: 53.097%\n",
      "Epoch: 120, Batch: 0, Loss: 0.1412537395954132\n",
      "Epoch: 120, Batch: 2995, Loss: 0.3261273205280304\n",
      "Epoch: 120, Accuracy: 48.22%\n",
      "  Loss: 25%: 0.190579 50%: 0.233330 75%: 0.281258\n",
      "   Avg: 0.255604\n",
      "Validation Accuracy: 53.106%\n",
      "Epoch: 121, Batch: 0, Loss: 0.1730925440788269\n",
      "Epoch: 121, Batch: 2995, Loss: 0.24498622119426727\n",
      "Epoch: 121, Accuracy: 47.95%\n",
      "  Loss: 25%: 0.191826 50%: 0.230823 75%: 0.279419\n",
      "   Avg: 0.254891\n",
      "Validation Accuracy: 53.084%\n",
      "Epoch: 122, Batch: 0, Loss: 0.3411625027656555\n",
      "Epoch: 122, Batch: 2995, Loss: 0.25621700286865234\n",
      "Epoch: 122, Accuracy: 48.53%\n",
      "  Loss: 25%: 0.189360 50%: 0.230027 75%: 0.276635\n",
      "   Avg: 0.252817\n",
      "Validation Accuracy: 52.990%\n",
      "Epoch: 123, Batch: 0, Loss: 0.23814493417739868\n",
      "Epoch: 123, Batch: 2995, Loss: 0.22163355350494385\n",
      "Epoch: 123, Accuracy: 48.62%\n",
      "  Loss: 25%: 0.186958 50%: 0.227191 75%: 0.271728\n",
      "   Avg: 0.247426\n",
      "Validation Accuracy: 52.941%\n",
      "Epoch: 124, Batch: 0, Loss: 0.26720207929611206\n",
      "Epoch: 124, Batch: 2995, Loss: 0.09552697092294693\n",
      "Epoch: 124, Accuracy: 48.56%\n",
      "  Loss: 25%: 0.188033 50%: 0.225339 75%: 0.270274\n",
      "   Avg: 0.246727\n",
      "Validation Accuracy: 53.026%\n",
      "Epoch: 125, Batch: 0, Loss: 0.1851017326116562\n",
      "Epoch: 125, Batch: 2995, Loss: 0.26437097787857056\n",
      "Epoch: 125, Accuracy: 48.89%\n",
      "  Loss: 25%: 0.184771 50%: 0.223152 75%: 0.268494\n",
      "   Avg: 0.243645\n",
      "Validation Accuracy: 53.066%\n",
      "Epoch: 126, Batch: 0, Loss: 0.18408514559268951\n",
      "Epoch: 126, Batch: 2995, Loss: 0.08278076350688934\n",
      "Epoch: 126, Accuracy: 49.11%\n",
      "  Loss: 25%: 0.184850 50%: 0.224850 75%: 0.270521\n",
      "   Avg: 0.245805\n",
      "Validation Accuracy: 53.048%\n",
      "Epoch: 127, Batch: 0, Loss: 0.25329166650772095\n",
      "Epoch: 127, Batch: 2995, Loss: 0.13108301162719727\n",
      "Epoch: 127, Accuracy: 49.19%\n",
      "  Loss: 25%: 0.182480 50%: 0.222250 75%: 0.265776\n",
      "   Avg: 0.240792\n",
      "Validation Accuracy: 53.075%\n",
      "Epoch: 128, Batch: 0, Loss: 0.26202547550201416\n",
      "Epoch: 128, Batch: 2995, Loss: 0.17319931089878082\n",
      "Epoch: 128, Accuracy: 49.23%\n",
      "  Loss: 25%: 0.182601 50%: 0.222586 75%: 0.266351\n",
      "   Avg: 0.241212\n",
      "Validation Accuracy: 52.972%\n",
      "Epoch: 129, Batch: 0, Loss: 0.17138352990150452\n",
      "Epoch: 129, Batch: 2995, Loss: 0.23548154532909393\n",
      "Epoch: 129, Accuracy: 49.26%\n",
      "  Loss: 25%: 0.182833 50%: 0.219100 75%: 0.265752\n",
      "   Avg: 0.239020\n",
      "Validation Accuracy: 53.079%\n",
      "Epoch: 130, Batch: 0, Loss: 0.2014465183019638\n",
      "Epoch: 130, Batch: 2995, Loss: 0.16393330693244934\n",
      "Epoch: 130, Accuracy: 49.42%\n",
      "  Loss: 25%: 0.181910 50%: 0.219741 75%: 0.262703\n",
      "   Avg: 0.236583\n",
      "Validation Accuracy: 52.865%\n",
      "Epoch: 131, Batch: 0, Loss: 0.3026745021343231\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 1022 # *14 close to 1024\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.225})\n",
    "trainFor(50, log_freq=DATA_SIZE, target_acc=0.6)\n",
    "# (223mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 35132\n",
      "  Total: 41941\n",
      "Epoch: 131, Batch: 0, Loss: 0.17456796765327454\n",
      "Epoch: 131, Batch: 2995, Loss: 0.2147127389907837\n",
      "Epoch: 131, Accuracy: 49.08%\n",
      "  Loss: 25%: 0.182142 50%: 0.219519 75%: 0.261854\n",
      "   Avg: 0.238503\n",
      "Validation Accuracy: 53.039%\n",
      "Epoch: 132, Batch: 0, Loss: 0.15447185933589935\n",
      "Epoch: 132, Batch: 2995, Loss: 0.23203356564044952\n",
      "Epoch: 132, Accuracy: 49.53%\n",
      "  Loss: 25%: 0.179635 50%: 0.218030 75%: 0.260219\n",
      "   Avg: 0.233673\n",
      "Validation Accuracy: 53.182%\n",
      "Epoch: 133, Batch: 0, Loss: 0.22216513752937317\n",
      "Epoch: 133, Batch: 2995, Loss: 0.225952610373497\n",
      "Epoch: 133, Accuracy: 49.67%\n",
      "  Loss: 25%: 0.179488 50%: 0.215952 75%: 0.258133\n",
      "   Avg: 0.232541\n",
      "Validation Accuracy: 52.972%\n",
      "Epoch: 134, Batch: 0, Loss: 0.2670586109161377\n",
      "Epoch: 134, Batch: 2995, Loss: 0.2001418173313141\n",
      "Epoch: 134, Accuracy: 50.15%\n",
      "  Loss: 25%: 0.175179 50%: 0.213433 75%: 0.257488\n",
      "   Avg: 0.230615\n",
      "Validation Accuracy: 52.919%\n",
      "Epoch: 135, Batch: 0, Loss: 0.31423643231391907\n",
      "Epoch: 135, Batch: 2995, Loss: 0.11538270115852356\n",
      "Epoch: 135, Accuracy: 50.29%\n",
      "  Loss: 25%: 0.175594 50%: 0.211208 75%: 0.255133\n",
      "   Avg: 0.227585\n",
      "Validation Accuracy: 52.959%\n",
      "Epoch: 136, Batch: 0, Loss: 0.29710689187049866\n",
      "Epoch: 136, Batch: 2995, Loss: 0.0789015144109726\n",
      "Epoch: 136, Accuracy: 50.39%\n",
      "  Loss: 25%: 0.175648 50%: 0.211855 75%: 0.252455\n",
      "   Avg: 0.226782\n",
      "Validation Accuracy: 53.071%\n",
      "Epoch: 137, Batch: 0, Loss: 0.16495665907859802\n",
      "Epoch: 137, Batch: 2995, Loss: 0.24261213839054108\n",
      "Epoch: 137, Accuracy: 50.61%\n",
      "  Loss: 25%: 0.173598 50%: 0.210634 75%: 0.251748\n",
      "   Avg: 0.225276\n",
      "Validation Accuracy: 52.919%\n",
      "Epoch: 138, Batch: 0, Loss: 0.22825747728347778\n",
      "Epoch: 138, Batch: 2995, Loss: 0.4262847304344177\n",
      "Epoch: 138, Accuracy: 50.50%\n",
      "  Loss: 25%: 0.173226 50%: 0.209946 75%: 0.251387\n",
      "   Avg: 0.224787\n",
      "Validation Accuracy: 53.053%\n",
      "Epoch: 139, Batch: 0, Loss: 0.2160070389509201\n",
      "Epoch: 139, Batch: 2995, Loss: 0.13261882960796356\n",
      "Epoch: 139, Accuracy: 50.48%\n",
      "  Loss: 25%: 0.173365 50%: 0.209577 75%: 0.249731\n",
      "   Avg: 0.224192\n",
      "Validation Accuracy: 52.825%\n",
      "Epoch: 140, Batch: 0, Loss: 0.07996378093957901\n",
      "Epoch: 140, Batch: 2995, Loss: 0.18721552193164825\n",
      "Epoch: 140, Accuracy: 50.85%\n",
      "  Loss: 25%: 0.170554 50%: 0.207321 75%: 0.248070\n",
      "   Avg: 0.221317\n",
      "Validation Accuracy: 52.790%\n",
      "Epoch: 141, Batch: 0, Loss: 0.3222982585430145\n",
      "Epoch: 141, Batch: 2995, Loss: 0.9178605675697327\n",
      "Epoch: 141, Accuracy: 51.22%\n",
      "  Loss: 25%: 0.169504 50%: 0.206563 75%: 0.244897\n",
      "   Avg: 0.219600\n",
      "Validation Accuracy: 53.048%\n",
      "Epoch: 142, Batch: 0, Loss: 0.2691981792449951\n",
      "Epoch: 142, Batch: 2995, Loss: 0.24003756046295166\n",
      "Epoch: 142, Accuracy: 51.40%\n",
      "  Loss: 25%: 0.169106 50%: 0.204174 75%: 0.247392\n",
      "   Avg: 0.218406\n",
      "Validation Accuracy: 52.901%\n",
      "Epoch: 143, Batch: 0, Loss: 0.17719309031963348\n",
      "Epoch: 143, Batch: 2995, Loss: 0.15425394475460052\n",
      "Epoch: 143, Accuracy: 51.35%\n",
      "  Loss: 25%: 0.168944 50%: 0.204503 75%: 0.243055\n",
      "   Avg: 0.217610\n",
      "Validation Accuracy: 52.901%\n",
      "Epoch: 144, Batch: 0, Loss: 0.2338138222694397\n",
      "Epoch: 144, Batch: 2995, Loss: 0.2070518136024475\n",
      "Epoch: 144, Accuracy: 51.63%\n",
      "  Loss: 25%: 0.167856 50%: 0.202702 75%: 0.243695\n",
      "   Avg: 0.215708\n",
      "Validation Accuracy: 52.990%\n",
      "Epoch: 145, Batch: 0, Loss: 0.18831443786621094\n",
      "Epoch: 145, Batch: 2995, Loss: 0.2211708277463913\n",
      "Epoch: 145, Accuracy: 51.82%\n",
      "  Loss: 25%: 0.165964 50%: 0.203234 75%: 0.243830\n",
      "   Avg: 0.214658\n",
      "Validation Accuracy: 53.004%\n",
      "Epoch: 146, Batch: 0, Loss: 0.2037527710199356\n",
      "Epoch: 146, Batch: 2995, Loss: 0.18083885312080383\n",
      "Epoch: 146, Accuracy: 51.81%\n",
      "  Loss: 25%: 0.166053 50%: 0.199619 75%: 0.240191\n",
      "   Avg: 0.212864\n",
      "Validation Accuracy: 52.834%\n",
      "Epoch: 147, Batch: 0, Loss: 0.20729103684425354\n",
      "Epoch: 147, Batch: 2995, Loss: 0.15167874097824097\n",
      "Epoch: 147, Accuracy: 52.05%\n",
      "  Loss: 25%: 0.164374 50%: 0.199613 75%: 0.239411\n",
      "   Avg: 0.211620\n",
      "Validation Accuracy: 53.182%\n",
      "Epoch: 148, Batch: 0, Loss: 0.17676162719726562\n",
      "Epoch: 148, Batch: 2995, Loss: 0.19715066254138947\n",
      "Epoch: 148, Accuracy: 52.28%\n",
      "  Loss: 25%: 0.162871 50%: 0.198474 75%: 0.237964\n",
      "   Avg: 0.211478\n",
      "Validation Accuracy: 52.955%\n",
      "Epoch: 149, Batch: 0, Loss: 0.17041398584842682\n",
      "Epoch: 149, Batch: 2995, Loss: 0.4120252728462219\n",
      "Epoch: 149, Accuracy: 52.49%\n",
      "  Loss: 25%: 0.161357 50%: 0.197457 75%: 0.237993\n",
      "   Avg: 0.209921\n",
      "Validation Accuracy: 53.004%\n",
      "Epoch: 150, Batch: 0, Loss: 0.2096111923456192\n",
      "Epoch: 150, Batch: 2995, Loss: 0.26320451498031616\n",
      "Epoch: 150, Accuracy: 52.73%\n",
      "  Loss: 25%: 0.161869 50%: 0.194943 75%: 0.232168\n",
      "   Avg: 0.205882\n",
      "Validation Accuracy: 52.848%\n",
      "Epoch: 151, Batch: 0, Loss: 0.23914119601249695\n",
      "Epoch: 151, Batch: 2995, Loss: 0.24244233965873718\n",
      "Epoch: 151, Accuracy: 52.98%\n",
      "  Loss: 25%: 0.160600 50%: 0.194629 75%: 0.234619\n",
      "   Avg: 0.206015\n",
      "Validation Accuracy: 52.856%\n",
      "Epoch: 152, Batch: 0, Loss: 0.17236745357513428\n",
      "Epoch: 152, Batch: 2995, Loss: 0.1849837303161621\n",
      "Epoch: 152, Accuracy: 53.29%\n",
      "  Loss: 25%: 0.157948 50%: 0.191419 75%: 0.229557\n",
      "   Avg: 0.201900\n",
      "Validation Accuracy: 52.883%\n",
      "Epoch: 153, Batch: 0, Loss: 0.15406402945518494\n",
      "Epoch: 153, Batch: 2995, Loss: 0.17802506685256958\n",
      "Epoch: 153, Accuracy: 53.33%\n",
      "  Loss: 25%: 0.159392 50%: 0.191431 75%: 0.229610\n",
      "   Avg: 0.202287\n",
      "Validation Accuracy: 52.843%\n",
      "Epoch: 154, Batch: 0, Loss: 0.22241804003715515\n",
      "Epoch: 154, Batch: 2995, Loss: 0.2500067353248596\n",
      "Epoch: 154, Accuracy: 53.69%\n",
      "  Loss: 25%: 0.157723 50%: 0.188545 75%: 0.228617\n",
      "   Avg: 0.199496\n",
      "Validation Accuracy: 52.856%\n",
      "Epoch: 155, Batch: 0, Loss: 0.1266290843486786\n",
      "Epoch: 155, Batch: 2995, Loss: 0.1894208788871765\n",
      "Epoch: 155, Accuracy: 53.69%\n",
      "  Loss: 25%: 0.154511 50%: 0.191379 75%: 0.228879\n",
      "   Avg: 0.200202\n",
      "Validation Accuracy: 52.687%\n",
      "Epoch: 156, Batch: 0, Loss: 0.12649598717689514\n",
      "Epoch: 156, Batch: 2995, Loss: 0.1534498631954193\n",
      "Epoch: 156, Accuracy: 53.95%\n",
      "  Loss: 25%: 0.154188 50%: 0.188899 75%: 0.226617\n",
      "   Avg: 0.198893\n",
      "Validation Accuracy: 52.848%\n",
      "Epoch: 157, Batch: 0, Loss: 0.4237060844898224\n",
      "Epoch: 157, Batch: 2995, Loss: 0.1487126350402832\n",
      "Epoch: 157, Accuracy: 54.24%\n",
      "  Loss: 25%: 0.155976 50%: 0.187156 75%: 0.224270\n",
      "   Avg: 0.197119\n",
      "Validation Accuracy: 52.821%\n",
      "Epoch: 158, Batch: 0, Loss: 0.2461422085762024\n",
      "Epoch: 158, Batch: 2995, Loss: 0.23494763672351837\n",
      "Epoch: 158, Accuracy: 54.61%\n",
      "  Loss: 25%: 0.153444 50%: 0.185941 75%: 0.223068\n",
      "   Avg: 0.195149\n",
      "Validation Accuracy: 52.812%\n",
      "Epoch: 159, Batch: 0, Loss: 0.14680062234401703\n",
      "Epoch: 159, Batch: 2995, Loss: 0.19267389178276062\n",
      "Epoch: 159, Accuracy: 54.88%\n",
      "  Loss: 25%: 0.151981 50%: 0.185152 75%: 0.220581\n",
      "   Avg: 0.193829\n",
      "Validation Accuracy: 52.745%\n",
      "Epoch: 160, Batch: 0, Loss: 0.17400358617305756\n",
      "Epoch: 160, Batch: 2995, Loss: 0.1689974069595337\n",
      "Epoch: 160, Accuracy: 55.17%\n",
      "  Loss: 25%: 0.148760 50%: 0.183310 75%: 0.220203\n",
      "   Avg: 0.191307\n",
      "Validation Accuracy: 52.843%\n",
      "Epoch: 161, Batch: 0, Loss: 0.10361282527446747\n",
      "Epoch: 161, Batch: 2995, Loss: 0.19020679593086243\n",
      "Epoch: 161, Accuracy: 54.97%\n",
      "  Loss: 25%: 0.150440 50%: 0.183268 75%: 0.220865\n",
      "   Avg: 0.192364\n",
      "Validation Accuracy: 52.812%\n",
      "Epoch: 162, Batch: 0, Loss: 0.1307583898305893\n",
      "Epoch: 162, Batch: 2995, Loss: 0.28710678219795227\n",
      "Epoch: 162, Accuracy: 55.77%\n",
      "  Loss: 25%: 0.147826 50%: 0.180152 75%: 0.219766\n",
      "   Avg: 0.189962\n",
      "Validation Accuracy: 52.776%\n",
      "Epoch: 163, Batch: 0, Loss: 0.20852915942668915\n",
      "Epoch: 163, Batch: 2995, Loss: 0.15895438194274902\n",
      "Epoch: 163, Accuracy: 55.74%\n",
      "  Loss: 25%: 0.146458 50%: 0.178671 75%: 0.217282\n",
      "   Avg: 0.188308\n",
      "Validation Accuracy: 52.883%\n",
      "Epoch: 164, Batch: 0, Loss: 0.1827256828546524\n",
      "Epoch: 164, Batch: 2995, Loss: 0.175968199968338\n",
      "Epoch: 164, Accuracy: 55.89%\n",
      "  Loss: 25%: 0.145810 50%: 0.179438 75%: 0.216572\n",
      "   Avg: 0.188304\n",
      "Validation Accuracy: 52.772%\n",
      "Epoch: 165, Batch: 0, Loss: 0.18635544180870056\n",
      "Epoch: 165, Batch: 2995, Loss: 0.12888622283935547\n",
      "Epoch: 165, Accuracy: 55.92%\n",
      "  Loss: 25%: 0.144977 50%: 0.178216 75%: 0.215082\n",
      "   Avg: 0.185798\n",
      "Validation Accuracy: 52.861%\n",
      "Epoch: 166, Batch: 0, Loss: 0.17755290865898132\n",
      "Epoch: 166, Batch: 2995, Loss: 0.3118989169597626\n",
      "Epoch: 166, Accuracy: 56.74%\n",
      "  Loss: 25%: 0.145369 50%: 0.174663 75%: 0.210551\n",
      "   Avg: 0.183285\n",
      "Validation Accuracy: 52.785%\n",
      "Epoch: 167, Batch: 0, Loss: 0.21569401025772095\n",
      "Epoch: 167, Batch: 2995, Loss: 0.1439850926399231\n",
      "Epoch: 167, Accuracy: 56.70%\n",
      "  Loss: 25%: 0.142086 50%: 0.173870 75%: 0.208752\n",
      "   Avg: 0.181668\n",
      "Validation Accuracy: 52.607%\n",
      "Epoch: 168, Batch: 0, Loss: 0.1436850130558014\n",
      "Epoch: 168, Batch: 2995, Loss: 0.1044338047504425\n",
      "Epoch: 168, Accuracy: 57.03%\n",
      "  Loss: 25%: 0.140973 50%: 0.172750 75%: 0.209615\n",
      "   Avg: 0.180560\n",
      "Validation Accuracy: 52.763%\n",
      "Epoch: 169, Batch: 0, Loss: 0.13769902288913727\n",
      "Epoch: 169, Batch: 2995, Loss: 0.17737945914268494\n",
      "Epoch: 169, Accuracy: 56.84%\n",
      "  Loss: 25%: 0.142967 50%: 0.173362 75%: 0.208406\n",
      "   Avg: 0.181033\n",
      "Validation Accuracy: 52.611%\n",
      "Epoch: 170, Batch: 0, Loss: 0.2274743914604187\n",
      "Epoch: 170, Batch: 2995, Loss: 0.2665488123893738\n",
      "Epoch: 170, Accuracy: 57.14%\n",
      "  Loss: 25%: 0.139566 50%: 0.170753 75%: 0.207355\n",
      "   Avg: 0.177908\n",
      "Validation Accuracy: 52.607%\n",
      "Epoch: 171, Batch: 0, Loss: 0.14465494453907013\n",
      "Epoch: 171, Batch: 2995, Loss: 0.13071167469024658\n",
      "Epoch: 171, Accuracy: 57.77%\n",
      "  Loss: 25%: 0.137563 50%: 0.168443 75%: 0.203131\n",
      "   Avg: 0.175312\n",
      "Validation Accuracy: 52.660%\n",
      "Epoch: 172, Batch: 0, Loss: 0.14957986772060394\n",
      "Epoch: 172, Batch: 2995, Loss: 0.1758527010679245\n",
      "Epoch: 172, Accuracy: 58.24%\n",
      "  Loss: 25%: 0.137057 50%: 0.166947 75%: 0.202921\n",
      "   Avg: 0.175115\n",
      "Validation Accuracy: 52.584%\n",
      "Epoch: 173, Batch: 0, Loss: 0.1380343735218048\n",
      "Epoch: 173, Batch: 2995, Loss: 0.2019529938697815\n",
      "Epoch: 173, Accuracy: 58.35%\n",
      "  Loss: 25%: 0.134828 50%: 0.165604 75%: 0.199026\n",
      "   Avg: 0.171554\n",
      "Validation Accuracy: 52.633%\n",
      "Epoch: 174, Batch: 0, Loss: 0.09876792877912521\n",
      "Epoch: 174, Batch: 2995, Loss: 0.579631507396698\n",
      "Epoch: 174, Accuracy: 58.99%\n",
      "  Loss: 25%: 0.133837 50%: 0.166010 75%: 0.198646\n",
      "   Avg: 0.171503\n",
      "Validation Accuracy: 52.562%\n",
      "Epoch: 175, Batch: 0, Loss: 0.1412682980298996\n",
      "Epoch: 175, Batch: 2995, Loss: 0.18162181973457336\n",
      "Epoch: 175, Accuracy: 59.22%\n",
      "  Loss: 25%: 0.131703 50%: 0.163297 75%: 0.198768\n",
      "   Avg: 0.170599\n",
      "Validation Accuracy: 52.611%\n",
      "Epoch: 176, Batch: 0, Loss: 0.1854919046163559\n",
      "Epoch: 176, Batch: 2995, Loss: 0.1270764172077179\n",
      "Epoch: 176, Accuracy: 59.13%\n",
      "  Loss: 25%: 0.131486 50%: 0.162598 75%: 0.196359\n",
      "   Avg: 0.168890\n",
      "Validation Accuracy: 52.611%\n",
      "Epoch: 177, Batch: 0, Loss: 0.17302939295768738\n",
      "Epoch: 177, Batch: 2995, Loss: 0.09811057895421982\n",
      "Epoch: 177, Accuracy: 59.53%\n",
      "  Loss: 25%: 0.131153 50%: 0.160969 75%: 0.197289\n",
      "   Avg: 0.167698\n",
      "Validation Accuracy: 52.522%\n",
      "Epoch: 178, Batch: 0, Loss: 0.1023058295249939\n",
      "Epoch: 178, Batch: 2995, Loss: 0.19970811903476715\n",
      "Epoch: 178, Accuracy: 59.78%\n",
      "  Loss: 25%: 0.128916 50%: 0.160004 75%: 0.194708\n",
      "   Avg: 0.166857\n",
      "Validation Accuracy: 52.611%\n",
      "Epoch: 179, Batch: 0, Loss: 0.15987038612365723\n",
      "Epoch: 179, Batch: 2995, Loss: 0.04370387643575668\n",
      "Epoch: 179, Accuracy: 59.99%\n",
      "  Loss: 25%: 0.127257 50%: 0.156363 75%: 0.193639\n",
      "   Avg: 0.165443\n",
      "Validation Accuracy: 52.633%\n",
      "Epoch: 180, Batch: 0, Loss: 0.14608030021190643\n",
      "Epoch: 180, Batch: 2995, Loss: 0.11598122864961624\n",
      "Epoch: 180, Accuracy: 60.32%\n",
      "  Loss: 25%: 0.126317 50%: 0.155354 75%: 0.190750\n",
      "   Avg: 0.162608\n",
      "Validation Accuracy: 52.495%\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 1022 # *14 close to 1024\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.225})\n",
    "trainFor(50, log_freq=DATA_SIZE, target_acc=0.6)\n",
    "# (473mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "  Total: 6809\n",
      "Validation Accuracy: 80.276%\n",
      "Concepts loaded;\n",
      "    - noise: 15614\n",
      "  Total: 15615\n",
      "Validation Accuracy: 40.384%\n"
     ]
    }
   ],
   "source": [
    "# Break down of validation per concept\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 76510\n",
      "  Total: 83319\n",
      "Epoch: 181, Batch: 0, Loss: 0.1759694367647171\n",
      "Epoch: 181, Batch: 5951, Loss: 0.22194238007068634\n",
      "Epoch: 181, Accuracy: 49.46%\n",
      "  Loss: 25%: 0.177602 50%: 0.217874 75%: 0.265804\n",
      "   Avg: 0.242470\n",
      "Validation Accuracy: 52.830%\n",
      "Epoch: 182, Batch: 0, Loss: 0.25460365414619446\n",
      "Epoch: 182, Batch: 5951, Loss: 0.21128690242767334\n",
      "Epoch: 182, Accuracy: 49.48%\n",
      "  Loss: 25%: 0.175104 50%: 0.212107 75%: 0.255886\n",
      "   Avg: 0.235241\n",
      "Validation Accuracy: 52.905%\n",
      "Epoch: 183, Batch: 0, Loss: 0.12572143971920013\n",
      "Epoch: 183, Batch: 5951, Loss: 0.33139023184776306\n",
      "Epoch: 183, Accuracy: 49.27%\n",
      "  Loss: 25%: 0.172943 50%: 0.209403 75%: 0.251747\n",
      "   Avg: 0.229739\n",
      "Validation Accuracy: 53.004%\n",
      "Epoch: 184, Batch: 0, Loss: 0.2354583591222763\n",
      "Epoch: 184, Batch: 5951, Loss: 0.17928846180438995\n",
      "Epoch: 184, Accuracy: 49.76%\n",
      "  Loss: 25%: 0.172795 50%: 0.206543 75%: 0.248675\n",
      "   Avg: 0.226555\n",
      "Validation Accuracy: 52.888%\n",
      "Epoch: 185, Batch: 0, Loss: 0.3152928948402405\n",
      "Epoch: 185, Batch: 5951, Loss: 0.2537960112094879\n",
      "Epoch: 185, Accuracy: 49.71%\n",
      "  Loss: 25%: 0.169415 50%: 0.206337 75%: 0.248528\n",
      "   Avg: 0.224546\n",
      "Validation Accuracy: 53.066%\n",
      "Epoch: 186, Batch: 0, Loss: 0.13190074265003204\n",
      "Epoch: 186, Batch: 5951, Loss: 0.24124428629875183\n",
      "Epoch: 186, Accuracy: 49.88%\n",
      "  Loss: 25%: 0.168619 50%: 0.203905 75%: 0.245822\n",
      "   Avg: 0.221270\n",
      "Validation Accuracy: 52.914%\n",
      "Epoch: 187, Batch: 0, Loss: 0.17863640189170837\n",
      "Epoch: 187, Batch: 5951, Loss: 0.26061293482780457\n",
      "Epoch: 187, Accuracy: 50.28%\n",
      "  Loss: 25%: 0.168085 50%: 0.202624 75%: 0.242696\n",
      "   Avg: 0.219301\n",
      "Validation Accuracy: 52.941%\n",
      "Epoch: 188, Batch: 0, Loss: 0.27418604493141174\n",
      "Epoch: 188, Batch: 5951, Loss: 0.15130357444286346\n",
      "Epoch: 188, Accuracy: 50.61%\n",
      "  Loss: 25%: 0.165971 50%: 0.199951 75%: 0.241438\n",
      "   Avg: 0.217038\n",
      "Validation Accuracy: 52.879%\n",
      "Epoch: 189, Batch: 0, Loss: 0.16989213228225708\n",
      "Epoch: 189, Batch: 5951, Loss: 0.2346327155828476\n",
      "Epoch: 189, Accuracy: 50.42%\n",
      "  Loss: 25%: 0.165432 50%: 0.200590 75%: 0.240036\n",
      "   Avg: 0.216463\n",
      "Validation Accuracy: 52.790%\n",
      "Epoch: 190, Batch: 0, Loss: 0.13766248524188995\n",
      "Epoch: 190, Batch: 5951, Loss: 0.2691914737224579\n",
      "Epoch: 190, Accuracy: 50.49%\n",
      "  Loss: 25%: 0.163948 50%: 0.199425 75%: 0.237080\n",
      "   Avg: 0.213604\n",
      "Validation Accuracy: 52.803%\n",
      "Epoch: 191, Batch: 0, Loss: 0.11564627289772034\n",
      "RuntimeError: DefaultCPUAllocator: not enough memory: you tried to allocate 2240000 bytes.\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 1022 # *14 close to 1024\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.49})\n",
    "trainFor(50, log_freq=DATA_SIZE, target_acc=0.7)\n",
    "# (147mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 76510\n",
      "  Total: 83319\n",
      "Epoch: 191, Batch: 0, Loss: 0.1820286512374878\n",
      "Epoch: 191, Batch: 5951, Loss: 0.10562223941087723\n",
      "Epoch: 191, Accuracy: 50.85%\n",
      "  Loss: 25%: 0.164790 50%: 0.199412 75%: 0.238296\n",
      "   Avg: 0.214035\n",
      "Validation Accuracy: 53.124%\n",
      "Epoch: 192, Batch: 0, Loss: 0.1497276872396469\n",
      "Epoch: 192, Batch: 5951, Loss: 0.18680252134799957\n",
      "Epoch: 192, Accuracy: 50.98%\n",
      "  Loss: 25%: 0.162247 50%: 0.196092 75%: 0.236591\n",
      "   Avg: 0.211390\n",
      "Validation Accuracy: 52.803%\n",
      "Epoch: 193, Batch: 0, Loss: 0.19556422531604767\n",
      "Epoch: 193, Batch: 5951, Loss: 0.280161052942276\n",
      "Epoch: 193, Accuracy: 51.34%\n",
      "  Loss: 25%: 0.160275 50%: 0.194838 75%: 0.233409\n",
      "   Avg: 0.209014\n",
      "Validation Accuracy: 53.097%\n",
      "Epoch: 194, Batch: 0, Loss: 0.2834548056125641\n",
      "Epoch: 194, Batch: 5951, Loss: 0.6966380476951599\n",
      "Epoch: 194, Accuracy: 51.55%\n",
      "  Loss: 25%: 0.159822 50%: 0.194443 75%: 0.231409\n",
      "   Avg: 0.207654\n",
      "Validation Accuracy: 53.151%\n",
      "Epoch: 195, Batch: 0, Loss: 0.11288994550704956\n",
      "Epoch: 195, Batch: 5951, Loss: 0.1698908507823944\n",
      "Epoch: 195, Accuracy: 51.70%\n",
      "  Loss: 25%: 0.159832 50%: 0.192139 75%: 0.230805\n",
      "   Avg: 0.206031\n",
      "Validation Accuracy: 52.941%\n",
      "Epoch: 196, Batch: 0, Loss: 0.14972242712974548\n",
      "Epoch: 196, Batch: 5951, Loss: 0.16492556035518646\n",
      "Epoch: 196, Accuracy: 52.18%\n",
      "  Loss: 25%: 0.157479 50%: 0.190821 75%: 0.228025\n",
      "   Avg: 0.203893\n",
      "Validation Accuracy: 52.883%\n",
      "Epoch: 197, Batch: 0, Loss: 0.20100075006484985\n",
      "Epoch: 197, Batch: 5951, Loss: 0.2130565196275711\n",
      "Epoch: 197, Accuracy: 52.11%\n",
      "  Loss: 25%: 0.156594 50%: 0.189072 75%: 0.227841\n",
      "   Avg: 0.203247\n",
      "Validation Accuracy: 52.963%\n",
      "Epoch: 198, Batch: 0, Loss: 0.18655453622341156\n",
      "Epoch: 198, Batch: 5951, Loss: 0.1593368798494339\n",
      "Epoch: 198, Accuracy: 52.39%\n",
      "  Loss: 25%: 0.156194 50%: 0.187701 75%: 0.225506\n",
      "   Avg: 0.200879\n",
      "Validation Accuracy: 52.905%\n",
      "Epoch: 199, Batch: 0, Loss: 0.24816332757472992\n",
      "Epoch: 199, Batch: 5951, Loss: 0.10066870599985123\n",
      "Epoch: 199, Accuracy: 52.73%\n",
      "  Loss: 25%: 0.152662 50%: 0.186729 75%: 0.224295\n",
      "   Avg: 0.198552\n",
      "Validation Accuracy: 52.861%\n",
      "Epoch: 200, Batch: 0, Loss: 0.18519984185695648\n",
      "Epoch: 200, Batch: 5951, Loss: 0.25817492604255676\n",
      "Epoch: 200, Accuracy: 52.97%\n",
      "  Loss: 25%: 0.152649 50%: 0.186452 75%: 0.224015\n",
      "   Avg: 0.198277\n",
      "Validation Accuracy: 52.986%\n",
      "Epoch: 201, Batch: 0, Loss: 0.16506406664848328\n",
      "Epoch: 201, Batch: 5951, Loss: 0.20575696229934692\n",
      "Epoch: 201, Accuracy: 53.08%\n",
      "  Loss: 25%: 0.152702 50%: 0.184572 75%: 0.222248\n",
      "   Avg: 0.196713\n",
      "Validation Accuracy: 52.848%\n",
      "Epoch: 202, Batch: 0, Loss: 0.23441407084465027\n",
      "Epoch: 202, Batch: 5951, Loss: 0.3520592451095581\n",
      "Epoch: 202, Accuracy: 53.45%\n",
      "  Loss: 25%: 0.151167 50%: 0.183634 75%: 0.219966\n",
      "   Avg: 0.194563\n",
      "Validation Accuracy: 53.106%\n",
      "Epoch: 203, Batch: 0, Loss: 0.33637237548828125\n",
      "Epoch: 203, Batch: 5951, Loss: 0.10094496607780457\n",
      "Epoch: 203, Accuracy: 53.78%\n",
      "  Loss: 25%: 0.150781 50%: 0.182061 75%: 0.218928\n",
      "   Avg: 0.192700\n",
      "Validation Accuracy: 53.030%\n",
      "Epoch: 204, Batch: 0, Loss: 0.19431081414222717\n",
      "Epoch: 204, Batch: 5951, Loss: 0.11201415956020355\n",
      "Epoch: 204, Accuracy: 53.87%\n",
      "  Loss: 25%: 0.149685 50%: 0.180462 75%: 0.217404\n",
      "   Avg: 0.192059\n",
      "Validation Accuracy: 52.888%\n",
      "Epoch: 205, Batch: 0, Loss: 0.1797298640012741\n",
      "Epoch: 205, Batch: 5951, Loss: 0.10290796309709549\n",
      "Epoch: 205, Accuracy: 54.20%\n",
      "  Loss: 25%: 0.147557 50%: 0.181123 75%: 0.216545\n",
      "   Avg: 0.190382\n",
      "Validation Accuracy: 52.883%\n",
      "Epoch: 206, Batch: 0, Loss: 0.3373429775238037\n",
      "Epoch: 206, Batch: 5951, Loss: 0.22212053835391998\n",
      "Epoch: 206, Accuracy: 54.58%\n",
      "  Loss: 25%: 0.146073 50%: 0.178143 75%: 0.214584\n",
      "   Avg: 0.188370\n",
      "Validation Accuracy: 52.928%\n",
      "Epoch: 207, Batch: 0, Loss: 0.27096864581108093\n",
      "Epoch: 207, Batch: 5951, Loss: 0.17658790946006775\n",
      "Epoch: 207, Accuracy: 54.59%\n",
      "  Loss: 25%: 0.145885 50%: 0.178028 75%: 0.214129\n",
      "   Avg: 0.187949\n",
      "Validation Accuracy: 52.848%\n",
      "Epoch: 208, Batch: 0, Loss: 0.14156758785247803\n",
      "Epoch: 208, Batch: 5951, Loss: 0.12636590003967285\n",
      "Epoch: 208, Accuracy: 55.04%\n",
      "  Loss: 25%: 0.143817 50%: 0.175486 75%: 0.211177\n",
      "   Avg: 0.184893\n",
      "Validation Accuracy: 52.700%\n",
      "Epoch: 209, Batch: 0, Loss: 0.14634786546230316\n",
      "Epoch: 209, Batch: 5951, Loss: 0.2053554803133011\n",
      "Epoch: 209, Accuracy: 55.38%\n",
      "  Loss: 25%: 0.142735 50%: 0.175249 75%: 0.211024\n",
      "   Avg: 0.185058\n",
      "Validation Accuracy: 52.843%\n",
      "Epoch: 210, Batch: 0, Loss: 0.15068452060222626\n",
      "RuntimeError: DefaultCPUAllocator: not enough memory: you tried to allocate 2240000 bytes.\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 1022 # *14 close to 1024\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.49})\n",
    "trainFor(50, log_freq=DATA_SIZE, target_acc=0.7)\n",
    "# (229mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch crashed - leading to emergency saving\n",
    "save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "Validation Accuracy: 52.932%\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "  Total: 6809\n",
      "Validation Accuracy: 80.291%\n",
      "Concepts loaded;\n",
      "    - noise: 15614\n",
      "  Total: 15615\n",
      "Validation Accuracy: 41.005%\n"
     ]
    }
   ],
   "source": [
    "# Validate the model saved correctly\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 140528\n",
      "  Total: 147337\n",
      "Epoch: 210, Batch: 0, Loss: 0.24935071170330048\n",
      "Epoch: 210, Batch: 10524, Loss: 0.14365918934345245\n",
      "Epoch: 210, Accuracy: 48.09%\n",
      "  Loss: 25%: 0.173191 50%: 0.209463 75%: 0.249764\n",
      "   Avg: 0.228281\n",
      "Validation Accuracy: 53.182%\n",
      "Epoch: 211, Batch: 0, Loss: 0.484810471534729\n",
      "Epoch: 211, Batch: 10524, Loss: 0.1400684267282486\n",
      "Epoch: 211, Accuracy: 48.27%\n",
      "  Loss: 25%: 0.171612 50%: 0.206248 75%: 0.245603\n",
      "   Avg: 0.224276\n",
      "Validation Accuracy: 53.204%\n",
      "Epoch: 212, Batch: 0, Loss: 0.1532992422580719\n",
      "Epoch: 212, Batch: 10524, Loss: 0.0006325695430859923\n",
      "Epoch: 212, Accuracy: 48.22%\n",
      "  Loss: 25%: 0.170276 50%: 0.204755 75%: 0.242843\n",
      "   Avg: 0.220793\n",
      "Validation Accuracy: 53.035%\n",
      "Epoch: 213, Batch: 0, Loss: 0.20600691437721252\n",
      "Epoch: 213, Batch: 10524, Loss: 0.0707259476184845\n",
      "Epoch: 213, Accuracy: 48.49%\n",
      "  Loss: 25%: 0.168891 50%: 0.202694 75%: 0.241886\n",
      "   Avg: 0.218966\n",
      "Validation Accuracy: 53.186%\n",
      "Epoch: 214, Batch: 0, Loss: 0.11710269004106522\n",
      "Epoch: 214, Batch: 10524, Loss: 0.00039651678525842726\n",
      "Epoch: 214, Accuracy: 48.21%\n",
      "  Loss: 25%: 0.169241 50%: 0.203020 75%: 0.240751\n",
      "   Avg: 0.218926\n",
      "Validation Accuracy: 53.004%\n",
      "Epoch: 215, Batch: 0, Loss: 0.24390177428722382\n",
      "Epoch: 215, Batch: 10524, Loss: 0.06970348954200745\n",
      "Epoch: 215, Accuracy: 48.64%\n",
      "  Loss: 25%: 0.168021 50%: 0.201160 75%: 0.239734\n",
      "   Avg: 0.217055\n",
      "Validation Accuracy: 53.338%\n",
      "Epoch: 216, Batch: 0, Loss: 0.15025655925273895\n",
      "Epoch: 216, Batch: 10524, Loss: 0.008078107610344887\n",
      "Epoch: 216, Accuracy: 48.79%\n",
      "  Loss: 25%: 0.165785 50%: 0.199781 75%: 0.238153\n",
      "   Avg: 0.214567\n",
      "Validation Accuracy: 53.262%\n",
      "Epoch: 217, Batch: 0, Loss: 0.21220816671848297\n",
      "Epoch: 217, Batch: 10524, Loss: 0.0769050121307373\n",
      "Epoch: 217, Accuracy: 48.82%\n",
      "  Loss: 25%: 0.167264 50%: 0.199284 75%: 0.237425\n",
      "   Avg: 0.214258\n",
      "Validation Accuracy: 53.253%\n",
      "Epoch: 218, Batch: 0, Loss: 0.19061556458473206\n",
      "Epoch: 218, Batch: 10524, Loss: 0.00046329511678777635\n",
      "Epoch: 218, Accuracy: 49.00%\n",
      "  Loss: 25%: 0.164644 50%: 0.198565 75%: 0.235597\n",
      "   Avg: 0.212398\n",
      "Validation Accuracy: 53.213%\n",
      "Epoch: 219, Batch: 0, Loss: 0.19540199637413025\n",
      "Epoch: 219, Batch: 10524, Loss: 0.022615374997258186\n",
      "Epoch: 219, Accuracy: 49.04%\n",
      "  Loss: 25%: 0.164490 50%: 0.197026 75%: 0.235531\n",
      "   Avg: 0.211420\n",
      "Validation Accuracy: 53.160%\n",
      "Epoch: 220, Batch: 0, Loss: 0.2539191246032715\n",
      "Epoch: 220, Batch: 10524, Loss: 0.07464168965816498\n",
      "Epoch: 220, Accuracy: 49.21%\n",
      "  Loss: 25%: 0.163750 50%: 0.195993 75%: 0.233938\n",
      "   Avg: 0.210664\n",
      "Validation Accuracy: 53.311%\n",
      "Epoch: 221, Batch: 0, Loss: 0.13495735824108124\n",
      "Epoch: 221, Batch: 10524, Loss: 0.11940675973892212\n",
      "Epoch: 221, Accuracy: 49.39%\n",
      "  Loss: 25%: 0.162886 50%: 0.195294 75%: 0.232887\n",
      "   Avg: 0.209206\n",
      "Validation Accuracy: 53.218%\n",
      "Epoch: 222, Batch: 0, Loss: 0.19618456065654755\n",
      "Epoch: 222, Batch: 10524, Loss: 0.017163889482617378\n",
      "Epoch: 222, Accuracy: 49.68%\n",
      "  Loss: 25%: 0.161987 50%: 0.194032 75%: 0.231896\n",
      "   Avg: 0.207977\n",
      "Validation Accuracy: 53.093%\n",
      "Epoch: 223, Batch: 0, Loss: 0.21550768613815308\n",
      "Epoch: 223, Batch: 10524, Loss: 0.04788040369749069\n",
      "Epoch: 223, Accuracy: 49.90%\n",
      "  Loss: 25%: 0.161827 50%: 0.193703 75%: 0.229645\n",
      "   Avg: 0.206735\n",
      "Validation Accuracy: 53.062%\n",
      "Epoch: 224, Batch: 0, Loss: 0.24241986870765686\n",
      "Epoch: 224, Batch: 10524, Loss: 0.20222845673561096\n",
      "Epoch: 224, Accuracy: 49.82%\n",
      "  Loss: 25%: 0.160476 50%: 0.193889 75%: 0.229972\n",
      "   Avg: 0.206189\n",
      "Validation Accuracy: 53.048%\n",
      "Epoch: 225, Batch: 0, Loss: 0.14375357329845428\n",
      "Epoch: 225, Batch: 10524, Loss: 0.2765099108219147\n",
      "Epoch: 225, Accuracy: 50.27%\n",
      "  Loss: 25%: 0.159822 50%: 0.191309 75%: 0.228040\n",
      "   Avg: 0.204235\n",
      "Validation Accuracy: 53.097%\n",
      "Epoch: 226, Batch: 0, Loss: 0.11278132349252701\n",
      "Epoch: 226, Batch: 10524, Loss: 0.6148223280906677\n",
      "Epoch: 226, Accuracy: 50.22%\n",
      "  Loss: 25%: 0.158904 50%: 0.191321 75%: 0.227882\n",
      "   Avg: 0.203376\n",
      "Validation Accuracy: 53.195%\n",
      "Epoch: 227, Batch: 0, Loss: 0.1858789473772049\n",
      "Epoch: 227, Batch: 10524, Loss: 0.0685286596417427\n",
      "Epoch: 227, Accuracy: 50.32%\n",
      "  Loss: 25%: 0.158333 50%: 0.190516 75%: 0.227225\n",
      "   Avg: 0.202512\n",
      "Validation Accuracy: 53.302%\n",
      "Epoch: 228, Batch: 0, Loss: 0.17631907761096954\n",
      "Epoch: 228, Batch: 10524, Loss: 0.2416338473558426\n",
      "Epoch: 228, Accuracy: 50.67%\n",
      "  Loss: 25%: 0.157914 50%: 0.189432 75%: 0.224905\n",
      "   Avg: 0.200855\n",
      "Validation Accuracy: 53.120%\n",
      "Epoch: 229, Batch: 0, Loss: 0.24869632720947266\n",
      "Epoch: 229, Batch: 10524, Loss: 0.003622440854087472\n",
      "Epoch: 229, Accuracy: 50.90%\n",
      "  Loss: 25%: 0.156626 50%: 0.188478 75%: 0.224750\n",
      "   Avg: 0.199874\n",
      "Validation Accuracy: 53.173%\n",
      "Epoch: 230, Batch: 0, Loss: 0.14873717725276947\n",
      "Epoch: 230, Batch: 10524, Loss: 0.5484054684638977\n",
      "Epoch: 230, Accuracy: 50.94%\n",
      "  Loss: 25%: 0.156429 50%: 0.188423 75%: 0.224165\n",
      "   Avg: 0.199762\n",
      "Validation Accuracy: 52.999%\n",
      "Epoch: 231, Batch: 0, Loss: 0.19018657505512238\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 2044 # *14 close to 1024\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.9})\n",
    "trainFor(50, log_freq=DATA_SIZE, target_acc=0.75)\n",
    "# (635mins)\n",
    "# (total 2525mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 15614\n",
      "  Total: 22423\n",
      "Concepts loaded;\n",
      "    - vocabulary: 6808\n",
      "    - noise: 140528\n",
      "  Total: 147337\n",
      "Epoch: 231, Batch: 0, Loss: 0.2609182894229889\n",
      "Epoch: 231, Batch: 10524, Loss: 0.018615350127220154\n",
      "Epoch: 231, Accuracy: 50.96%\n",
      "  Loss: 25%: 0.156389 50%: 0.187656 75%: 0.224919\n",
      "   Avg: 0.199664\n",
      "Total Seq Accuracy: 53.142%\n",
      "Average Sequence: 90.449%\n",
      "Epoch: 232, Batch: 0, Loss: 0.15666547417640686\n",
      "Epoch: 232, Batch: 10524, Loss: 0.2910940945148468\n",
      "Epoch: 232, Accuracy: 51.26%\n",
      "  Loss: 25%: 0.154557 50%: 0.185810 75%: 0.223254\n",
      "   Avg: 0.197851\n",
      "Total Seq Accuracy: 53.160%\n",
      "Average Sequence: 90.445%\n",
      "Epoch: 233, Batch: 0, Loss: 0.20547236502170563\n",
      "Epoch: 233, Batch: 10524, Loss: 0.0004840803158003837\n",
      "Epoch: 233, Accuracy: 51.53%\n",
      "  Loss: 25%: 0.153975 50%: 0.185541 75%: 0.221745\n",
      "   Avg: 0.196544\n",
      "Total Seq Accuracy: 53.218%\n",
      "Average Sequence: 90.456%\n",
      "Epoch: 234, Batch: 0, Loss: 0.27715635299682617\n",
      "Epoch: 234, Batch: 10524, Loss: 0.25293126702308655\n",
      "Epoch: 234, Accuracy: 51.82%\n",
      "  Loss: 25%: 0.153175 50%: 0.184081 75%: 0.219979\n",
      "   Avg: 0.194818\n",
      "Total Seq Accuracy: 53.048%\n",
      "Average Sequence: 90.451%\n",
      "Epoch: 235, Batch: 0, Loss: 0.22562071681022644\n",
      "Epoch: 235, Batch: 10524, Loss: 0.002188540995121002\n",
      "Epoch: 235, Accuracy: 51.79%\n",
      "  Loss: 25%: 0.152208 50%: 0.184005 75%: 0.219539\n",
      "   Avg: 0.194209\n",
      "Total Seq Accuracy: 52.959%\n",
      "Average Sequence: 90.417%\n",
      "Epoch: 236, Batch: 0, Loss: 0.2143665999174118\n",
      "Epoch: 236, Batch: 10524, Loss: 0.1533225029706955\n",
      "Epoch: 236, Accuracy: 52.29%\n",
      "  Loss: 25%: 0.150308 50%: 0.181263 75%: 0.218329\n",
      "   Avg: 0.191664\n",
      "Total Seq Accuracy: 52.941%\n",
      "Average Sequence: 90.415%\n",
      "Epoch: 237, Batch: 0, Loss: 0.155844584107399\n",
      "Epoch: 237, Batch: 10524, Loss: 0.1112360805273056\n",
      "Epoch: 237, Accuracy: 52.41%\n",
      "  Loss: 25%: 0.149270 50%: 0.180657 75%: 0.215131\n",
      "   Avg: 0.190298\n",
      "Total Seq Accuracy: 53.044%\n",
      "Average Sequence: 90.428%\n",
      "Epoch: 238, Batch: 0, Loss: 0.17006930708885193\n",
      "Epoch: 238, Batch: 10524, Loss: 0.018928231671452522\n",
      "Epoch: 238, Accuracy: 52.72%\n",
      "  Loss: 25%: 0.148296 50%: 0.180179 75%: 0.213922\n",
      "   Avg: 0.188934\n",
      "Total Seq Accuracy: 52.919%\n",
      "Average Sequence: 90.400%\n",
      "Epoch: 239, Batch: 0, Loss: 0.1624288260936737\n",
      "Epoch: 239, Batch: 10524, Loss: 0.07836275547742844\n",
      "Epoch: 239, Accuracy: 53.05%\n",
      "  Loss: 25%: 0.147384 50%: 0.178142 75%: 0.212728\n",
      "   Avg: 0.187054\n",
      "Total Seq Accuracy: 53.093%\n",
      "Average Sequence: 90.420%\n",
      "Epoch: 240, Batch: 0, Loss: 0.17445063591003418\n",
      "Epoch: 240, Batch: 10524, Loss: 0.23442593216896057\n",
      "Epoch: 240, Accuracy: 53.44%\n",
      "  Loss: 25%: 0.145216 50%: 0.176100 75%: 0.211181\n",
      "   Avg: 0.185378\n",
      "Total Seq Accuracy: 52.892%\n",
      "Average Sequence: 90.408%\n",
      "Epoch: 241, Batch: 0, Loss: 0.1514521837234497\n",
      "Epoch: 241, Batch: 10524, Loss: 0.24692629277706146\n",
      "Epoch: 241, Accuracy: 53.38%\n",
      "  Loss: 25%: 0.145515 50%: 0.175865 75%: 0.209552\n",
      "   Avg: 0.184029\n",
      "Total Seq Accuracy: 52.843%\n",
      "Average Sequence: 90.370%\n",
      "Epoch: 242, Batch: 0, Loss: 0.16183389723300934\n",
      "Epoch: 242, Batch: 10524, Loss: 0.0024435033556073904\n",
      "Epoch: 242, Accuracy: 53.86%\n",
      "  Loss: 25%: 0.143238 50%: 0.173950 75%: 0.208680\n",
      "   Avg: 0.182224\n",
      "Total Seq Accuracy: 53.106%\n",
      "Average Sequence: 90.440%\n",
      "Epoch: 243, Batch: 0, Loss: 0.120327889919281\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "ACCUMULATION_STEPS = 1022 # *14 close to 1024\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.9})\n",
    "trainFor(50, log_freq=DATA_SIZE, target_acc=0.75)\n",
    "# (347mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCUMULATION_STEPS = 28 # *14 close to 32\n",
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.9})\n",
    "trainFor(50, log_freq=DATA_SIZE, target_acc=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_concept({\"vocabulary\": 1.0, \"noise\": 0.1}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"vocabulary\": 1.0}, validation=True)\n",
    "validate()\n",
    "apply_concept({\"noise\": 0.1}, validation=True)\n",
    "validate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
