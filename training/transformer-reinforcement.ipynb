{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import csv\n",
    "\n",
    "def load_token_mapping(csv_path):\n",
    "    token_to_string = {}\n",
    "    with open(csv_path, 'r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            token_id, token_str = int(row[0]), row[1]\n",
    "            token_to_string[token_id] = token_str\n",
    "    return token_to_string\n",
    "\n",
    "token_mapping = load_token_mapping('tokens.csv')\n",
    "model_path = '../saved_models/epoch_36'\n",
    "\n",
    "class SimpleBART(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleBART, self).__init__()\n",
    "\n",
    "        if os.path.exists(model_path):\n",
    "            self.bart = BartForConditionalGeneration.from_pretrained(model_path)\n",
    "            self.tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "        else:\n",
    "            raise ValueError(f\"Model not found at {model_path}. Please make sure the path is correct or set load_from_saved to False.\")\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.bart(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    def decode_beam_to_tokens(self, beam_output):\n",
    "        decoded_tokens = []\n",
    "        for token_id in beam_output[2:]:\n",
    "            if token_id == self.tokenizer.eos_token_id:\n",
    "                break\n",
    "            decoded_tokens.append(token_mapping.get(token_id.item(), \"<UNK>\"))  # default to \"<UNK>\" if token not found\n",
    "        return decoded_tokens\n",
    "\n",
    "model = SimpleBART()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> red horse\n",
      "Option 1: ['horse']\n",
      "  [2, 0, 457, 2, 1]\n",
      "Option 2: ['horse', 'red']\n",
      "  [2, 0, 457, 578, 2]\n",
      "Option 3: ['horse', 'rough']\n",
      "  [2, 0, 457, 211, 2]\n",
      "Option 4: ['horse', 'grey']\n",
      "  [2, 0, 457, 121, 2]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOption \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mdecode_beam_to_tokens(option_ids)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{\u001b[39;00moption_ids\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 26\u001b[0m choice \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(\u001b[39minput\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mWhich option is correct? (1/2/3/4): \u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m     27\u001b[0m chosen_translation_ids \u001b[39m=\u001b[39m translation_ids[choice \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m     29\u001b[0m target_ids \u001b[39m=\u001b[39m chosen_translation_ids\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m) \u001b[39m# Add batch dimension\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "source_text = input(\"Enter the source text: \")\n",
    "\n",
    "# Tokenize the input text\n",
    "input_ids = model.tokenizer.encode(source_text, return_tensors=\"pt\")\n",
    "\n",
    "print(f\"> {source_text}\")\n",
    "\n",
    "while True:\n",
    "    model.train()\n",
    "\n",
    "    # Beam search for top translations based on the input text\n",
    "    translation_ids = model.bart.generate(\n",
    "        input_ids,\n",
    "        num_beams=4,\n",
    "        max_length=200,\n",
    "        num_return_sequences=4,\n",
    "        eos_token_id=model.tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Display the options\n",
    "    for i, option_ids in enumerate(translation_ids, 1):\n",
    "        # Print the decoded strings for each option\n",
    "        print(f\"Option {i}: {model.decode_beam_to_tokens(option_ids)}\")\n",
    "        print(f\"  {option_ids.tolist()}\", flush=True)\n",
    "\n",
    "    choice = int(input(\"Which option is correct? (1/2/3/4): \"))\n",
    "    chosen_translation_ids = translation_ids[choice - 1]\n",
    "\n",
    "    target_ids = chosen_translation_ids.unsqueeze(0) # Add batch dimension\n",
    "\n",
    "    # Run the model again to get the logits for the original input\n",
    "    outputs = model(input_ids, None)\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Resize for the loss function\n",
    "    target_ids = target_ids[:, :logits.shape[1]]\n",
    "    logits = logits[:, :target_ids.shape[1]]\n",
    "\n",
    "    loss = criterion(logits.view(-1, logits.size(-1)), target_ids.view(-1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Loss: {loss.item()}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
